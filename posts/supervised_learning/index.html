<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Supervised Learning의 큰 그림 | MLBlog</title>
<meta name="keywords" content="">
<meta name="description" content="이번에는 머신러닝에서 지도학습(Supervised Learning)의 전반적인 시나리오에 대한 글입니다. 지도학습으로 머신러닝 모델을 학습시킨다는 것이 무엇인지 설명하는 기초적인 이론이에요. 지도학습은 흔히 인풋 데이터 $x$가 주어졌을 때, 타겟 데이터 $y$를 추정하는 모델, 즉, $y=f(x)$가 되는 함수 $f$를 학습시키는 기법이라고 간단하게 설명됩니다. 하지만 우리는 이것보다 조금 더 근본적인 시각에서, 큰 그림으로 시작해볼게요. 확률 통계적인 관점에서 지도학습은 인풋 데이터 $x$가 주어졌을 때 타겟 $y$가 어떤 확률 분포를 따르는지, 조건부 확률 분포를 추정해 보는 것이라고 볼 수 있습니다.">
<meta name="author" content="">
<link rel="canonical" href="http://repun.github.io/posts/supervised_learning/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.9d4f844eaa4f78f307fe7b60e91f30525e084db78986cd1660839e63f5a041cb.css" integrity="sha256-nU&#43;ETqpPePMH/ntg6R8wUl4ITbeJhs0WYIOeY/WgQcs=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="http://repun.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://repun.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://repun.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://repun.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="http://repun.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  }
};
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
  <meta property="og:title" content="Supervised Learning의 큰 그림" />
<meta property="og:description" content="이번에는 머신러닝에서 지도학습(Supervised Learning)의 전반적인 시나리오에 대한 글입니다. 지도학습으로 머신러닝 모델을 학습시킨다는 것이 무엇인지 설명하는 기초적인 이론이에요. 지도학습은 흔히 인풋 데이터 $x$가 주어졌을 때, 타겟 데이터 $y$를 추정하는 모델, 즉, $y=f(x)$가 되는 함수 $f$를 학습시키는 기법이라고 간단하게 설명됩니다. 하지만 우리는 이것보다 조금 더 근본적인 시각에서, 큰 그림으로 시작해볼게요. 확률 통계적인 관점에서 지도학습은 인풋 데이터 $x$가 주어졌을 때 타겟 $y$가 어떤 확률 분포를 따르는지, 조건부 확률 분포를 추정해 보는 것이라고 볼 수 있습니다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://repun.github.io/posts/supervised_learning/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-05-22T16:37:57+09:00" />
<meta property="article:modified_time" content="2021-05-22T16:37:57+09:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Supervised Learning의 큰 그림"/>
<meta name="twitter:description" content="이번에는 머신러닝에서 지도학습(Supervised Learning)의 전반적인 시나리오에 대한 글입니다. 지도학습으로 머신러닝 모델을 학습시킨다는 것이 무엇인지 설명하는 기초적인 이론이에요. 지도학습은 흔히 인풋 데이터 $x$가 주어졌을 때, 타겟 데이터 $y$를 추정하는 모델, 즉, $y=f(x)$가 되는 함수 $f$를 학습시키는 기법이라고 간단하게 설명됩니다. 하지만 우리는 이것보다 조금 더 근본적인 시각에서, 큰 그림으로 시작해볼게요. 확률 통계적인 관점에서 지도학습은 인풋 데이터 $x$가 주어졌을 때 타겟 $y$가 어떤 확률 분포를 따르는지, 조건부 확률 분포를 추정해 보는 것이라고 볼 수 있습니다."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://repun.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Supervised Learning의 큰 그림",
      "item": "http://repun.github.io/posts/supervised_learning/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Supervised Learning의 큰 그림",
  "name": "Supervised Learning의 큰 그림",
  "description": "이번에는 머신러닝에서 지도학습(Supervised Learning)의 전반적인 시나리오에 대한 글입니다. 지도학습으로 머신러닝 모델을 학습시킨다는 것이 무엇인지 설명하는 기초적인 이론이에요. 지도학습은 흔히 인풋 데이터 $x$가 주어졌을 때, 타겟 데이터 $y$를 추정하는 모델, 즉, $y=f(x)$가 되는 함수 $f$를 학습시키는 기법이라고 간단하게 설명됩니다. 하지만 우리는 이것보다 조금 더 근본적인 시각에서, 큰 그림으로 시작해볼게요. 확률 통계적인 관점에서 지도학습은 인풋 데이터 $x$가 주어졌을 때 타겟 $y$가 어떤 확률 분포를 따르는지, 조건부 확률 분포를 추정해 보는 것이라고 볼 수 있습니다.",
  "keywords": [
    
  ],
  "articleBody": "이번에는 머신러닝에서 지도학습(Supervised Learning)의 전반적인 시나리오에 대한 글입니다. 지도학습으로 머신러닝 모델을 학습시킨다는 것이 무엇인지 설명하는 기초적인 이론이에요. 지도학습은 흔히 인풋 데이터 $x$가 주어졌을 때, 타겟 데이터 $y$를 추정하는 모델, 즉, $y=f(x)$가 되는 함수 $f$를 학습시키는 기법이라고 간단하게 설명됩니다. 하지만 우리는 이것보다 조금 더 근본적인 시각에서, 큰 그림으로 시작해볼게요. 확률 통계적인 관점에서 지도학습은 인풋 데이터 $x$가 주어졌을 때 타겟 $y$가 어떤 확률 분포를 따르는지, 조건부 확률 분포를 추정해 보는 것이라고 볼 수 있습니다. 수식으로는 다음 확률 분포를 추정하는 것이지요.\n$$p(y|x)$$\n왜 추정이라고 하냐면 위 확률 분포가 정확히 어떻게 생겼는지 우리는 모르기 때문입니다. 예를 들어, 사람의 키와 몸무게가 주어지고 이를 이용해 나이의 분포를 알고 싶다고 해봅시다. 하지만 이 세상에서 인간이 가질 수 있는 키, 몸무게, 나이에 대한 정보를 모두 얻지 않는 이상 정확한 분포를 알아낼 수는 없습니다. 신만이 가능하겠지요. 그래서 우리는 머신러닝 모델과 약간의 데이터를 이용해 위 분포를 논리적으로 추정하는 것입니다.\n1. Bayesian 관점의 Supervised Learning $p(y|x)$를 추정하는 방법은 크게 두 가지로 나눌 수 있습니다. 첫번째는 $p(y|x)$를 직접 추정하는 방법입니다. 그리고 두번째는 $p(y|x)$를 직접 추정하는 대신 $p(x, y)$를 추정하는 방법입니다. $p(x, y)$를 추정하더라도 아래처럼 $p(y|x)$를 계산할 수 있습니다.\n$$p(y|x) = \\frac{p(x, y)}{p(x)} = \\frac{p(x, y)}{\\int p(x, y) dy}$$\n$p(y|x)$를 직접 추정하는 모델을 Discriminative 모델이라고 합니다. 그리고 $p(x, y)$를 추정하는 모델을 Generative 모델이라고 합니다. Generative 모델 쪽이 Discriminative 모델보다 가지는 정보가 많습니다. 위에서 봤듯이 $p(x, y)$를 알고 있다면 $p(y | x)$는 구할 수 있지만 반대로는 안되거든요. 쉽게 생각하면 Generative 모델 쪽이 상위 호환이라고 볼 수도 있겠네요. Discriminative 모델에는 $x$의 분포인 $p(x)$에 대한 정보가 없습니다. 즉, Discriminative 모델은 $p(y|x)$를 추정하는 데에 있어서 인풋 데이터 $x$가 어떤 분포를 가지는지는 신경쓰지 않습니다. 반대로 Generative 모델은 $x$와 $y$에 대한 모든 분포 정보를 가지고 있다고 볼 수 있습니다. 단순히 $x$가 주어졌을 때 $y$의 분포를 구하는 것을 넘어서 $x$, $y$를 분포에 맞게 샘플링하면 데이터를 생성할 수도 있습니다. 그래서 Generative에요.\nGenerative 모델이 상위 호환이니 일반적으로 Discriminative 모델보다 학습시키기 어렵습니다. 그래서 만약 우리가 단순히 $p(y|x)$에만 관심이 있다면 Discriminative 모델 쪽을 학습시키는 것이 간단하기도 하고, 예측 성능도 더 좋은 경우가 많습니다. 실제로 우리가 자주 사용하는 지도학습 머신러닝 모델, 신경망 모델이라던지 Decision Tree, 선형 회귀 모델 등은 대체로 Discriminative 모델의 형태로 학습됩니다.\n그럼 이제부터는 Discriminative 모델에 집중해서 이야기해봅시다. 우리는 $p(y|x)$를 추정하고 싶습니다. 하지만 아무 단서도 없으면 추정할 수 없습니다. 그건 추정이 아니고 찍는 거잖아요. 추정을 가능하게 해주는 단서인 데이터가 필요합니다. 흔히 머신러닝에서 학습 데이터셋이라고 불리지요. 데이터 $D$를 이용해 $p(y|x)$를 추정하는 것을 수식으로 나타내볼게요.\n$$p(y|x) \\approx p(y | x, D)$$\n$p(y|x)$는 우리가 알아내고 싶은 오리지날 확률 분포입니다. 그리고 데이터를 이용해 이 분포를 추정한 것이 바로 $p(y | x, D)$입니다. 여기에 추가로 우리는 모수가 있는 모델을 이용해서 이 추정 분포를 표현하고 싶습니다. 즉, $p(y | x, D)$ 분포를 파라미터 $\\theta$가 포함된 어떤 수식으로 모델링된 형태로 만들고 싶어요. $\\theta$가 무슨 값인지 우리는 아직 모릅니다. 그래서 우선은 확률 변수로써 취급할 겁니다. $\\theta$를 추가해서 다음과 같이 수식을 추가로 전개할 수 있습니다.\n$$p(y|x) \\approx p(y | x, D) = \\int p(y, \\theta | x, D) d\\theta$$\n$\\theta$가 가질 수 있는 모든 값과 그 확률을 고려해 $p(y | x, D)$를 나타냈습니다. 여기서 조건부 확률의 성질을 이용해 추가로 아래와 같이 수식을 전개할 수 있습니다.\n$$\\begin{align} p(y | x, D) \u0026= \\int p(y, \\theta | x, D) d\\theta \\\\ \u0026= \\int \\frac{p(y, \\theta, x, D)}{p(\\theta, x, D)} \\frac{p(\\theta, x, D)}{p(x, D)} d\\theta \\\\ \u0026= \\int \\underbrace{p(y | x, D, \\theta)}_{(A)} \\underbrace{p(\\theta | x, D)}_{(B)} d\\theta \\tag{1}\\label{1} \\end{align}$$\n위 수식 $\\eqref{1}$이 바로 우리가 지도학습에서 $p(y|x)$를 추정하기 위해 사용하는 수식입니다. 수식의 각 부분을 구분하기 위해 A와 B로 나누어 두었습니다. 하나씩 살펴볼게요. 먼저 A 부분을 봅시다. 파라미터 $\\theta$와 데이터 $D$가 있을 때, 인풋 데이터 $x$에 따른 타겟 $y$의 분포를 나타내는 부분입니다. 경우에 따라 다르지만 이 수식이 머신러닝 모델을 직접 나타내는 경우도 있습니다. 예를 들어 Logistic 회귀 모델을 생각해봅시다. Logistic 회귀 모델은 데이터 $D$를 이용해 학습한 모델의 파라미터 $\\theta$가 주어지면, $x$에 따라서 타겟이 0일지 1일지 Bernoulli 확률 분포로 예측합니다. 즉, Logistic 회귀 모델의 수식이 $p(y | x, D, \\theta)$ 부분이 되는 겁니다.\n다음은 수식 B 부분을 볼게요. 인풋 데이터 $x$와 학습 데이터 $D$에 따라서 모델의 파라미터 $\\theta$가 어떻게 분포하는지를 나타내는 조건부 확률입니다. 즉, B는 우리가 알고싶은 값 $\\theta$에 대한 Posterior 확률 분포를 나타내는 식입니다. 데이터 $D$와 인풋 데이터 $x$가 주어졌을 때 $\\theta$는 어떤 확정된 값이 아닌 이 분포를 따르는 확률변수가 됩니다.\n수식 $\\eqref{1}$의 A와 B를 분포를 구했다면 마지막으로 $\\theta$에 대해 적분을 해주어야 합니다. 그러면 결과적으로 우리가 원하는 좌항의 $p(y | x, D)$를 얻을 수 있게 됩니다. $p(y | x, D)$를 이용하면 완전히 정확하지는 않더라도 처음 보는 $x$가 주어졌을 때 $y$가 어떤 분포를 따르는지 알 수 있지요. 우리가 이 수식으로 예측하는 $y$ 역시 어떤 정해진 값이 아니고 확률 분포를 따르는 확률 변수가 됩니다. 이 조건부 확률 분포, $p(y | x, D)$는 인풋 $x$ 값에 대해 $y$를 예측하는 분포라고 해서 Predictive Distribution이라고도 부릅니다. 이렇게 Predictive Distribution을 계산해서 우리가 처음에 알고자했던 $p(y | x)$를 추정하는 것이 Bayesian 관점에서 바라본 지도학습의 큰 그림입니다.\n하지만 문제가 있습니다. 바로 수식 $\\eqref{1}$을 계산하는 것이 어렵다는 점입니다. A 부분은 비교적 간단하게 만들 수 있습니다. $\\theta$와 $D$에 따라 $x$가 주어졌을 때 $y$가 어떤 확률 분포를 따르는지 모델링 해주면 됩니다. 하지만 $\\theta$의 Posterior 분포인 B는 구하기가 까다롭습니다. 그리고 만약 B를 구했다고 하더라도 $\\theta$에 대해 적분을 하는 것 역시 쉽지 않습니다. 결론적으로 수식 $\\eqref{1}$을 직접 계산해서 Predictive Distribution을 구하는 것은 일반적으로 매우 어려운 작업이 됩니다. 물론 여러 가지 가정을 할 경우 계산할 수 있습니다. 예를 들어, 파라미터가 정규 분포를 따르고 선형 회귀 모델을 가정한다면 위 수식을 전부 계산할 수 있습니다. 이걸 Bayesian Linear Regression이라고 불러요. 하지만 대부분의 경우 이런식으로 직접 계산하는 것은 실전에 적극적으로 이용되기 보다는 이론적인 시나리오에서 그칩니다.\n2. 파라미터의 점추정으로 Predictive Distribution을 근사하는 법 자, 수식 $\\eqref{1}$을 풀어야 우리가 궁금한 $p(y|x)$를 추정할 수 있는데, 풀기 어렵다는 이야기까지 했습니다. 그래서 수학자들은 이걸 직접 푸는 대신에 간접적으로 풀거나 근사할 수 있는 많은 방법들을 제시해 왔습니다. 이 글에서 우리는 $\\theta$의 점추정을 통해 식 $\\eqref{1}$을 근사하는 시나리오를 자세히 살펴보도록 하겠습니다. 가장 흔하게 사용되는 지도학습 모델의 학습 전략이에요.\n우선 수식 $\\eqref{1}$을 우리가 자주 사용하는 시나리오에 맞게 조금 더 고쳐불게요. 보통 우리는 머신러닝 모델의 파라미터 $\\theta$를 학습 데이터셋 $D$를 이용해 추정합니다. 즉, $\\theta$가 어떤 값을 가질지는 $D$만 보고 결정한다는 뜻이지요. 그리고 인풋 데이터 $x$는 학습데이터 $D$와 직접 관련 없이 독립적으로 샘플링된 별개의 데이터지요. 따라서 Posterior 분포 $p(\\theta | x, D)$에서 $x$는 $D$랑 $\\theta$에 영향을 주지 않으므로 $p(\\theta | D)$로 나타낼 수 있습니다.\n마찬가지로 모델링 부분인 $p(y | x, D, \\theta)$도 만약 모델의 파라미터 $\\theta$가 학습 데이터 $D$에 의해 계산되어 주어졌다고 가정한다면 학습 데이터 $D$와 타겟 데이터 $y$는 독립입니다. 그래서 $p(y | x, \\theta)$로 나타낼 수 있습니다. 정리해서 수식 $\\eqref{1}$을 아래와 같이 나타내보겠습니다.\n$$\\begin{align} p(y | x, D) \u0026= \\int p(y | x, \\theta) p(\\theta | D) d\\theta \\tag{2} \\label{2} \\end{align}$$\n식이 살짝 깔끔해졌습니다. 이제부터는 수식 $\\eqref{1}$ 대신 $\\eqref{2}$를 이용해 Predictive Distribution을 구할 수 있는지 살펴보겠습니다. 우선 $\\theta$의 Posterior 분포인 $p(\\theta | D)$를 볼게요. Posterior 분포를 자세히 보기 위해 Bayes Rule을 이용해 Likelihood와 Prior의 곱 형태로 나타내 보겠습니다.\n$$ p(\\theta | D) = \\frac{p(D | \\theta) p(\\theta)}{p(D)} = \\frac{p(D | \\theta) p(\\theta)}{\\int p(D | \\theta) p(\\theta) d\\theta} $$\nLikelihood, Prior, 그리고 데이터 $D$의 분포인 $p(D)$를 안다면 Posterior 확률을 구할 수 있다는 걸 알 수 있습니다. 하지만 여전히 구하기는 어렵습니다. Likelihood인 $p(D | \\theta)$는 비교적 쉽게 알 수 있지만 Prior인 $p(\\theta)$는 모르는 경우가 많습니다. 혹시 Prior를 알고 있거나 적당한 분포로 가정하더라도 이번엔 분모에 들어있는 데이터의 분포 $p(D)$를 또 모르겠습니다. $p(D)$ 대신 $\\int p(D | \\theta) p(\\theta) d\\theta$를 계산하려고 해도 적분이 까다롭습니다.\n그래서 아까 말했듯이 일반적으로 우리는 $\\theta$의 Posterior 분포를 직접 계산하지는 않습니다. 대신 점추정 기법을 이용해 $\\theta$를 대충 추정하는 걸로 만족합니다. 다시 설명해볼게요. 위 수식대로라면 우리는 $D$에 따라 $\\theta$가 가질 수 있는 조건부 Posterior 확률 분포 전체를 구해야합니다. 하지만 이게 너무 어려우니 확률 분포 전체를 구하는 건 포기하고, 대신 $\\theta$를 가장 그럴듯한 하나의 값으로 추정을 해버리겠다는 것이지요.\n$\\theta$를 하나의 값으로 추정하면 까다로운 부분이 전부 사라집니다. 만약 우리가 $\\theta$를 $\\hat{\\theta}$로 추정했다고 하면 수식으로 다음과 같이 나타낼 수 있습니다.\n$$p(y|x) \\approx \\int p(y | x, \\theta) p(\\theta | D) d\\theta \\approx p(y | x, \\hat{\\theta})$$\n결국 $\\theta$를 하나의 값 $\\hat{\\theta}$로 추정하면, $p(y | x, \\hat{\\theta})$가 우리가 처음에 원했던 $p(y | x)$를 추정하게 되는 모양입니다. 이것이 바로 우리가 머신러닝 모델을 학습시킬 때 많이 사용하는 시나리오입니다. 혹시 회귀모델이나 딥러닝 등 지도학습 머신러닝 모델을 학습시켜본 경험이 있다면, 십중팔구 모델의 파라미터를 확률분포가 아니라 그냥 고정된 하나의 값으로 구했을 겁니다. 이건 위에서 본 것과 같이 Posterior 분포 전체를 구하기는 어려우니 파라미터의 점추정치를 구하는 것이 됩니다. 그리고 구한 하나의 파라미터 값으로 모델을 고정하고 인풋 데이터 $x$가 들어올 때 모델에서 계산한 $y$를 예측값으로 내보냅니다.\n물론 원래라면 $\\theta$의 Posterior 분포를 구해야 할 것을 점추정을 해버렸으니 부작용도 있습니다. 바로 오버피팅이에요. 지도학습에서 오버피팅이 생기는 이유가 여기에 있습니다. 데이터 $D$를 이용해 $\\theta$값을 하나로 추정하기 때문에 만약 데이터가 부족하거나 질이 안 좋을 경우 $\\theta$의 추정치가 부정확해지고 이는 오버피팅으로 이어집니다. 그럼 점추정을 하지 말고 $\\theta$의 Posterior를 구해서 모델을 만들면 데이터가 부족하더라도 오버피팅이 안 일어난다는 뜻인가요? 그렇게 볼 수 있습니다. 물론 이게 데이터가 부족해도 예측을 잘하는 『갓☆모델』을 만들 수 있다는 뜻은 아닙니다. Posterior 분포를 구했다고 하더라도 데이터가 부족하다면 Posterior는 Prior에 가까워집니다. Prior 분포가 데이터를 잘 나타내지 못한다면 예측된 분포 역시 부정확할 것이고, 만약 Prior를 잘 몰라서 대충 두루뭉술한 정규분포로 가정해서 사용했다면 모델의 예측값도 두루뭉술해집니다. 인풋 $x$가 들어왔을 때 $y$값이 이것도 될 수 있고 저것도 될 수 있는, 그런 애매한 분포를 반환해준다는 뜻이에요. 냅다 확신하듯 결과를 뱉어주는 오버피팅된 모델보다 이쪽이 나은지는 뭐 경우에 따라 다를 것 같습니다.\n3. 모델의 파라미터를 추정하는 방법 자, Posterior 분포는 구하기 어려우니 대신 $\\theta$를 하나의 값 $\\hat{\\theta}$로 점추정한다는 것 까지 이야기가 이어졌습니다. 그럼 이제부터 어떻게 이 값을 추정하는지 살펴보도록 합시다. 가장 흔하게 사용되는 방법은 바로 Maximum Likelihood Estimation(MLE)를 이용해 $\\theta$를 추정하는 것입니다. 즉, $\\theta$의 Likelihood를 가장 크게 만들어주는 값으로 $\\theta$를 추정하겠다는 이야기지요. 아래 최적화 문제를 푸는 것과 같습니다.\n$$\\hat{\\theta} = \\arg \\max_{\\theta} p(D | \\theta)$$\n이 시나리오에서 데이터 $D$ 안에는 보통 우리가 구하고자 하는 오리지널 분포 $p(y | x)$에서 독립적으로 샘플링 된 샘플들이 들어있습니다. 샘플링된 인풋, 타겟 데이터의 집합을 $X_{D}$, $Y_{D}$라고 해볼게요. 그럼 다음과 같이 식을 정리할 수 있습니다.\n$$\\begin{align}\n\\hat{\\theta} \u0026= \\arg \\max_{\\theta} p(D | \\theta) \\\\ \u0026= \\arg \\max_{\\theta} p(X_{D}, Y_{D} | \\theta) \\\\ \u0026= \\arg \\max_{\\theta} \\frac{p(Y_{D}, X_{D}, \\theta)}{p(\\theta)} \\\\ \u0026= \\arg \\max_{\\theta} \\frac{p(Y_{D}, X_{D}, \\theta)}{p(X_{D})p(\\theta)} \\\\ \u0026= \\arg \\max_{\\theta} \\frac{p(Y_{D}, X_{D}, \\theta)}{p(X_{D}, \\theta)} \\\\ \u0026= \\arg \\max_{\\theta} p(Y_{D} | X_{D}, \\theta) \\\\ \\end{align}$$\n$X_{D}$와 $Y_{D}$에는 각각 $n$개의 데이터가 들어있다고 하겠습니다. 풀어서 쓰면 $x_1, x_2, \\cdots x_n$과 $y_1, y_2, \\cdots y_n$이 들어있어요. 이 $(x_{i}, y_{i})$ 쌍을 서로 독립적으로 샘플링됐다고 했으니 수식을 다음과 같이 추가로 전개할 수 있습니다.\n$$\\begin{align} \\hat{\\theta} \u0026= \\arg \\max_{\\theta} p(Y_{D} | X_{D} \\theta) \\\\ \u0026= \\arg \\max_{\\theta} \\prod_{i=1}^{n} p(y_{i} | x_{i}, \\theta) \\tag{3} \\label{3} \\end{align}$$\n이 수식 $\\eqref{3}$을 이용하면 $\\theta$의 MLE를 구할 수 있습니다. 데이터셋 $D$에 들어있는 데이터 샘플들이 발생할 확률이 가장 커지도록 $\\theta$의 값을 추정하는 것이지요. 수식 $\\eqref{3}$을 $\\theta$에 대해 미분해서 값이 가장 커지게 만들어주는 $\\theta$를 계산하면 되겠습니다.\n하지만 사실 일반적으로 수식 $\\eqref{3}$을 그대로 계산에 사용하는 일은 별로 없습니다. 왜냐하면 수식 $\\eqref{3}$의 모양을 보면 서로 독립인 확률을 여러 번 곱해주는 모양인데 별로 좋은 모양이 아닙니다. 1보다 작은 확률을 $n$번 곱하다보면 값이 지나치게 0에 가까워져서 컴퓨터로 계산할 때 문제가 발생할 수 있거든요. Underflow가 발생합니다. 이런 문제를 예방하기 위해 우리는 식 $\\eqref{3}$에 $\\log$를 씌워서 곱셈을 덧셈 형태로 바꿀 겁니다. $\\log$를 씌워도 전체 수식을 가장 크게 만드는 $\\hat{\\theta}$값은 동일하기 때문에 최적화 문제의 답은 변하지 않습니다.\n$$\\begin{align} \\hat{\\theta} \u0026= \\arg \\max_{\\theta} \\prod_{i=1}^{n} p(y_{i} | x_{i}, \\theta) \\\\ \u0026= \\arg \\min_{\\theta} \\sum_{i=1}^{n} \\left[ -\\log p(y_{i} | x_{i}, \\theta) \\right] \\tag{4} \\label{4} \\end{align}$$\n수식 $\\eqref{4}$를 보면 $\\log$를 씌워서 확률의 곱셈을 덧셈 형식으로 바꾼 것 이외에도 $-1$을 곱해서 $\\arg \\max$를 $\\arg \\min$으로 바꾼 걸 알 수 있습니다. 이런 수학 최적화 문제는 보통 목적식을 최대화 하는 문제 보다는 최소화 문제를 기준으로 쓰는 경우가 관습적으로 많기 때문에 $-1$을 곱해서 최소화 문제로 바꿔줍니다. 이렇게 Likelihood에 $\\log$를 씌우고 $-1$을 곱한 것을 Negative Log-Likelihood(NLL)라고 부릅니다. 다시 말해, MLE로 구한 $\\theta$의 점추정치는 NLL을 가장 작게 만드는 $\\theta$의 점추정치라고도 표현할 수 있습니다. 완전히 똑같은 의미입니다.\n또 다른 관점에서도 바라볼 수 있습니다. $D$ 안에 데이터가 $n$개 들어있다고 했으니 위 수식을 $n$으로 나눠볼게요.\n$$\\begin{align} \\hat{\\theta} \u0026= \\arg \\min_{\\theta} \\sum_{i} \\left[ -\\log p(y_{i} | x_{i}, \\theta) \\right] \\\\ \u0026= \\arg \\min_{\\theta} \\sum_{i} \\left[ -\\frac{1}{n} \\log p(y_{i} | x_{i}, \\theta) \\right] \\\\ \u0026= \\arg \\min_{\\theta} \\sum_{i} \\left[ -p(x_{i}, y_{i}) \\log p(y_{i} | x_{i}, \\theta) \\right] \\\\ \u0026= \\arg \\min_{\\theta} \\sum_{i} \\left[ -p(y_{i} | x_{i}) \\log p(y_{i} | x_{i}, \\theta) \\right] \\\\ \u0026= \\arg \\min_{\\theta} H(p_{\\text{data}}, p_{\\text{model}}) \\tag{5} \\label{5} \\end{align}$$\n왜 $1/n$이 $p(x_{i}, y_{i})$가 되냐면 이건 Empirical Distribution입니다. 우리가 $n$개의 $(x, y)$ 데이터를 가지고 있으니 그 중 하나인 $(x_i, y_i)$가 발생할 확률은 경험적으로 $1/n$ 정도가 된다는 것이지요. 즉, 수식 $\\eqref{5}$에서 $p_{\\text{data}}$는 실재 데이터의 분포라기 보다는 데이터셋에서 유추한 경험적인 Empirical 분포입니다. $p_{\\text{model}}$은 $\\theta$에 따른 모델의 데이터 분포, $p(y_{i} | x_{i}, \\theta)$입니다. 결국 수식 $\\eqref{5}$은 NLL을 가장 작게 만드는 $\\theta$의 추정치는 $p_{\\text{data}}$와 $p_{\\text{model}}$의 Corss Entropy를 가장 작게 만드는 $\\hat{\\theta}$와 같다는 뜻을 나타냅니다. 지도학습 모델을 학습시킬 때 Cross Entropy Loss라는 걸 이용하는 경우가 많은데, 수식 $\\eqref{5}$를 이용하는 것이지요.\n조금만 더 나아가 볼게요. 수식 $\\eqref{5}$에서 상수를 더하거나 빼도 $\\hat{\\theta}$의 값은 변하지 않습니다. 따라서 다음과 같이 수식을 고쳐쓸 수 있습니다.\n$$\\begin{aligned} \\hat{\\theta} \u0026= \\arg \\min_{\\theta} H(p_{\\text{data}}, p_{\\text{model}}) \\\\ \u0026= \\arg \\min_{\\theta} \\left[ H(p_{\\text{data}}, p_{\\text{model}}) - H(p_{\\text{data}}) \\right] \\\\ \u0026= \\arg \\min_{\\theta} D_{KL}(p_{\\text{data}} || p_{\\text{model}}) \\end{aligned}$$\n이번엔 KL-Divergence로 수식이 정리되었습니다. $p_{\\text{data}}$와 $p_{\\text{model}}$의 KL-Divergence를 가장 작게 만드는 $\\theta$의 추정치도 역시 같은 의미가 됩니다. 정리해보겠습니다. MLE를 이용해 모델의 파라미터 $\\theta$의 추정치를 구하는 건 아래와 같이 네 가지로 표현할 수 있었습니다.\nLikelihood를 가장 크게 만드는(MLE) $\\theta$를 구한다. NLL을 가장 작게 만드는 $\\theta$를 구한다. Cross Entropy를 가장 작게 만드는 $\\theta$를 구한다. KL-Divergence를 가장 작게 만드는 $\\theta$를 구한다. 서로 다른 용어로 써있지만 결국 전부 같은 말입니다. 위 네 용어 모두 머신러닝에서 자주 등장하는 용어인데, 서로 따로따로 쓰이면 복잡해보이지만 이제 우리는 전부 같은 뜻이라는 걸 알았어요.\n자, 이렇게 조건부 확률 $p(y|x)$ 이야기 부터 시작해서 모델의 파라미터 $\\theta$를 점추정하여 근사하는 과정까지 살펴보았습니다. 물론 실전에서 머신러닝 모델을 지도학습 시킬 때에는 이런 과정은 생각하지 않아도 되는 경우가 대부분입니다. 계산은 컴퓨터가 해주고 학습 알고리즘은 똑똑하신 분들이 이미 다 짜주셨으니, 우린 그대로 가져다 쓰면 됩니다. 하지만 머신러닝 모델을 지도학습시키는게 무엇인지, 데이터로 모델의 파라미터를 구하는 것이 어떤 의미인지를 이해하고 대입해 볼 수 있다면 이런 내용을 공부하는 것도 의미가 없지는 않을 것 같습니다.\n참고 자료 Bishop, Christopher M. “Pattern Recognition and Machine Learning”\n",
  "wordCount" : "2267",
  "inLanguage": "en",
  "datePublished": "2021-05-22T16:37:57+09:00",
  "dateModified": "2021-05-22T16:37:57+09:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://repun.github.io/posts/supervised_learning/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "MLBlog",
    "logo": {
      "@type": "ImageObject",
      "url": "http://repun.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://repun.github.io/" accesskey="h" title="MLBlog (Alt + H)">MLBlog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Supervised Learning의 큰 그림
    </h1>
    <div class="post-meta"><span title='2021-05-22 16:37:57 +0900 KST'>May 22, 2021</span>

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#1-bayesian-%ea%b4%80%ec%a0%90%ec%9d%98-supervised-learning" aria-label="1. Bayesian 관점의 Supervised Learning">1. Bayesian 관점의 Supervised Learning</a></li>
                <li>
                    <a href="#2-%ed%8c%8c%eb%9d%bc%eb%af%b8%ed%84%b0%ec%9d%98-%ec%a0%90%ec%b6%94%ec%a0%95%ec%9c%bc%eb%a1%9c-predictive-distribution%ec%9d%84-%ea%b7%bc%ec%82%ac%ed%95%98%eb%8a%94-%eb%b2%95" aria-label="2. 파라미터의 점추정으로 Predictive Distribution을 근사하는 법">2. 파라미터의 점추정으로 Predictive Distribution을 근사하는 법</a></li>
                <li>
                    <a href="#3-%eb%aa%a8%eb%8d%b8%ec%9d%98-%ed%8c%8c%eb%9d%bc%eb%af%b8%ed%84%b0%eb%a5%bc-%ec%b6%94%ec%a0%95%ed%95%98%eb%8a%94-%eb%b0%a9%eb%b2%95" aria-label="3. 모델의 파라미터를 추정하는 방법">3. 모델의 파라미터를 추정하는 방법</a></li>
                <li>
                    <a href="#%ec%b0%b8%ea%b3%a0-%ec%9e%90%eb%a3%8c" aria-label="참고 자료">참고 자료</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>이번에는 머신러닝에서 지도학습(Supervised Learning)의 전반적인 시나리오에 대한 글입니다. 지도학습으로 머신러닝 모델을 학습시킨다는 것이 무엇인지 설명하는 기초적인 이론이에요. 지도학습은 흔히 인풋 데이터 $x$가 주어졌을 때, 타겟 데이터 $y$를 추정하는 모델, 즉, $y=f(x)$가 되는 함수 $f$를 학습시키는 기법이라고 간단하게 설명됩니다. 하지만 우리는 이것보다 조금 더 근본적인 시각에서, 큰 그림으로 시작해볼게요. 확률 통계적인 관점에서 지도학습은 인풋 데이터 $x$가 주어졌을 때 타겟 $y$가 어떤 확률 분포를 따르는지, 조건부 확률 분포를 추정해 보는 것이라고 볼 수 있습니다. 수식으로는 다음 확률 분포를 추정하는 것이지요.</p>
<p>$$p(y|x)$$</p>
<p>왜 추정이라고 하냐면 위 확률 분포가 정확히 어떻게 생겼는지 우리는 모르기 때문입니다. 예를 들어, 사람의 키와 몸무게가 주어지고 이를 이용해 나이의 분포를 알고 싶다고 해봅시다. 하지만 이 세상에서 인간이 가질 수 있는 키, 몸무게, 나이에 대한 정보를 모두 얻지 않는 이상 정확한 분포를 알아낼 수는 없습니다. 신만이 가능하겠지요. 그래서 우리는 머신러닝 모델과 약간의 데이터를 이용해 위 분포를 논리적으로 추정하는 것입니다.</p>
<h3 id="1-bayesian-관점의-supervised-learning">1. Bayesian 관점의 Supervised Learning<a hidden class="anchor" aria-hidden="true" href="#1-bayesian-관점의-supervised-learning">#</a></h3>
<p>$p(y|x)$를 추정하는 방법은 크게 두 가지로 나눌 수 있습니다. 첫번째는 $p(y|x)$를 직접 추정하는 방법입니다. 그리고 두번째는 $p(y|x)$를 직접 추정하는 대신 $p(x, y)$를 추정하는 방법입니다. $p(x, y)$를 추정하더라도 아래처럼 $p(y|x)$를 계산할 수 있습니다.</p>
<p>$$p(y|x) = \frac{p(x, y)}{p(x)} = \frac{p(x, y)}{\int p(x, y) dy}$$</p>
<p>$p(y|x)$를 직접 추정하는 모델을 Discriminative 모델이라고 합니다. 그리고 $p(x, y)$를 추정하는 모델을 Generative 모델이라고 합니다. Generative 모델 쪽이 Discriminative 모델보다 가지는 정보가 많습니다. 위에서 봤듯이 $p(x, y)$를 알고 있다면 $p(y | x)$는 구할 수 있지만 반대로는 안되거든요. 쉽게 생각하면 Generative 모델 쪽이 상위 호환이라고 볼 수도 있겠네요. Discriminative 모델에는 $x$의 분포인 $p(x)$에 대한 정보가 없습니다. 즉, Discriminative 모델은 $p(y|x)$를 추정하는 데에 있어서 인풋 데이터 $x$가 어떤 분포를 가지는지는 신경쓰지 않습니다. 반대로 Generative 모델은 $x$와 $y$에 대한 모든 분포 정보를 가지고 있다고 볼 수 있습니다. 단순히 $x$가 주어졌을 때 $y$의 분포를 구하는 것을 넘어서 $x$, $y$를 분포에 맞게 샘플링하면 데이터를 생성할 수도 있습니다. 그래서 Generative에요.</p>
<p>Generative 모델이 상위 호환이니 일반적으로 Discriminative 모델보다 학습시키기 어렵습니다. 그래서 만약 우리가 단순히 $p(y|x)$에만 관심이 있다면 Discriminative 모델 쪽을 학습시키는 것이 간단하기도 하고, 예측 성능도 더 좋은 경우가 많습니다. 실제로 우리가 자주 사용하는 지도학습 머신러닝 모델, 신경망 모델이라던지 Decision Tree, 선형 회귀 모델 등은 대체로 Discriminative 모델의 형태로 학습됩니다.</p>
<p>그럼 이제부터는 Discriminative 모델에 집중해서 이야기해봅시다. 우리는 $p(y|x)$를 추정하고 싶습니다. 하지만 아무 단서도 없으면 추정할 수 없습니다. 그건 추정이 아니고 찍는 거잖아요. 추정을 가능하게 해주는 단서인 데이터가 필요합니다. 흔히 머신러닝에서 학습 데이터셋이라고 불리지요. 데이터 $D$를 이용해 $p(y|x)$를 추정하는 것을 수식으로 나타내볼게요.</p>
<p>$$p(y|x) \approx p(y | x, D)$$</p>
<p>$p(y|x)$는 우리가 알아내고 싶은 오리지날 확률 분포입니다. 그리고 데이터를 이용해 이 분포를 추정한 것이 바로 $p(y | x, D)$입니다. 여기에 추가로 우리는 모수가 있는 모델을 이용해서 이 추정 분포를 표현하고 싶습니다. 즉, $p(y | x, D)$ 분포를 파라미터 $\theta$가 포함된 어떤 수식으로 모델링된 형태로 만들고 싶어요. $\theta$가 무슨 값인지 우리는 아직 모릅니다. 그래서 우선은 확률 변수로써 취급할 겁니다. $\theta$를 추가해서 다음과 같이 수식을 추가로 전개할 수 있습니다.</p>
<p>$$p(y|x) \approx p(y | x, D) = \int p(y, \theta | x, D) d\theta$$</p>
<p>$\theta$가 가질 수 있는 모든 값과 그 확률을 고려해 $p(y | x, D)$를 나타냈습니다. 여기서 조건부 확률의 성질을 이용해 추가로 아래와 같이 수식을 전개할 수 있습니다.</p>
<p>$$\begin{align}
p(y | x, D) &amp;= \int p(y, \theta | x, D) d\theta \\
&amp;= \int \frac{p(y, \theta, x, D)}{p(\theta, x, D)} \frac{p(\theta, x, D)}{p(x, D)} d\theta \\
&amp;= \int \underbrace{p(y | x, D, \theta)}_{(A)} \underbrace{p(\theta | x, D)}_{(B)} d\theta \tag{1}\label{1}
\end{align}$$</p>
<p>위 수식 $\eqref{1}$이 바로 우리가 지도학습에서 $p(y|x)$를 추정하기 위해 사용하는 수식입니다. 수식의 각 부분을 구분하기 위해 A와 B로 나누어 두었습니다. 하나씩 살펴볼게요. 먼저 A 부분을 봅시다. 파라미터 $\theta$와 데이터 $D$가 있을 때, 인풋 데이터 $x$에 따른 타겟 $y$의 분포를 나타내는 부분입니다. 경우에 따라 다르지만 이 수식이 머신러닝 모델을 직접 나타내는 경우도 있습니다. 예를 들어 Logistic 회귀 모델을 생각해봅시다. Logistic 회귀 모델은 데이터 $D$를 이용해 학습한 모델의 파라미터 $\theta$가 주어지면, $x$에 따라서 타겟이 0일지 1일지 Bernoulli 확률 분포로 예측합니다. 즉, Logistic 회귀 모델의 수식이 $p(y | x, D, \theta)$ 부분이 되는 겁니다.</p>
<p>다음은 수식 B 부분을 볼게요. 인풋 데이터 $x$와 학습 데이터 $D$에 따라서 모델의 파라미터 $\theta$가 어떻게 분포하는지를 나타내는 조건부 확률입니다. 즉, B는 우리가 알고싶은 값 $\theta$에 대한 Posterior 확률 분포를 나타내는 식입니다. 데이터 $D$와 인풋 데이터 $x$가 주어졌을 때 $\theta$는 어떤 확정된 값이 아닌 이 분포를 따르는 확률변수가 됩니다.</p>
<p>수식 $\eqref{1}$의 A와 B를 분포를 구했다면 마지막으로 $\theta$에 대해 적분을 해주어야 합니다. 그러면 결과적으로 우리가 원하는 좌항의 $p(y | x, D)$를 얻을 수 있게 됩니다. $p(y | x, D)$를 이용하면 완전히 정확하지는 않더라도 처음 보는 $x$가 주어졌을 때 $y$가 어떤 분포를 따르는지 알 수 있지요. 우리가 이 수식으로 예측하는 $y$ 역시 어떤 정해진 값이 아니고 확률 분포를 따르는 확률 변수가 됩니다. 이 조건부 확률 분포, $p(y | x, D)$는 인풋 $x$ 값에 대해 $y$를 예측하는 분포라고 해서 Predictive Distribution이라고도 부릅니다. 이렇게 Predictive Distribution을 계산해서 우리가 처음에 알고자했던 $p(y | x)$를 추정하는 것이 Bayesian 관점에서 바라본 지도학습의 큰 그림입니다.</p>
<p>하지만 문제가 있습니다. 바로 수식 $\eqref{1}$을 계산하는 것이 어렵다는 점입니다. A 부분은 비교적 간단하게 만들 수 있습니다. $\theta$와 $D$에 따라 $x$가 주어졌을 때 $y$가 어떤 확률 분포를 따르는지 모델링 해주면 됩니다. 하지만 $\theta$의 Posterior 분포인 B는 구하기가 까다롭습니다. 그리고 만약 B를 구했다고 하더라도 $\theta$에 대해 적분을 하는 것 역시 쉽지 않습니다. 결론적으로 수식 $\eqref{1}$을 직접 계산해서 Predictive Distribution을 구하는 것은 일반적으로 매우 어려운 작업이 됩니다. 물론 여러 가지 가정을 할 경우 계산할 수 있습니다. 예를 들어, 파라미터가 정규 분포를 따르고 선형 회귀 모델을 가정한다면 위 수식을 전부 계산할 수 있습니다. 이걸 Bayesian Linear Regression이라고 불러요. 하지만 대부분의 경우 이런식으로 직접 계산하는 것은 실전에 적극적으로 이용되기 보다는 이론적인 시나리오에서 그칩니다.</p>
<h3 id="2-파라미터의-점추정으로-predictive-distribution을-근사하는-법">2. 파라미터의 점추정으로 Predictive Distribution을 근사하는 법<a hidden class="anchor" aria-hidden="true" href="#2-파라미터의-점추정으로-predictive-distribution을-근사하는-법">#</a></h3>
<p>자, 수식 $\eqref{1}$을 풀어야 우리가 궁금한 $p(y|x)$를 추정할 수 있는데, 풀기 어렵다는 이야기까지 했습니다. 그래서 수학자들은 이걸 직접 푸는 대신에 간접적으로 풀거나 근사할 수 있는 많은 방법들을 제시해 왔습니다. 이 글에서 우리는 $\theta$의 점추정을 통해 식 $\eqref{1}$을 근사하는 시나리오를 자세히 살펴보도록 하겠습니다. 가장 흔하게 사용되는 지도학습 모델의 학습 전략이에요.</p>
<p>우선 수식 $\eqref{1}$을 우리가 자주 사용하는 시나리오에 맞게 조금 더 고쳐불게요. 보통 우리는 머신러닝 모델의 파라미터 $\theta$를 학습 데이터셋 $D$를 이용해 추정합니다. 즉, $\theta$가 어떤 값을 가질지는 $D$만 보고 결정한다는 뜻이지요. 그리고 인풋 데이터 $x$는 학습데이터 $D$와 직접 관련 없이 독립적으로 샘플링된 별개의 데이터지요. 따라서 Posterior 분포 $p(\theta | x, D)$에서 $x$는 $D$랑 $\theta$에 영향을 주지 않으므로 $p(\theta | D)$로 나타낼 수 있습니다.</p>
<p>마찬가지로 모델링 부분인 $p(y | x, D, \theta)$도 만약 모델의 파라미터 $\theta$가 학습 데이터 $D$에 의해 계산되어 주어졌다고 가정한다면 학습 데이터 $D$와 타겟 데이터 $y$는 독립입니다. 그래서 $p(y | x, \theta)$로 나타낼 수 있습니다. 정리해서 수식 $\eqref{1}$을 아래와 같이 나타내보겠습니다.</p>
<p>$$\begin{align}
p(y | x, D) &amp;= \int p(y | x, \theta) p(\theta | D) d\theta \tag{2} \label{2}
\end{align}$$</p>
<p>식이 살짝 깔끔해졌습니다. 이제부터는 수식 $\eqref{1}$ 대신 $\eqref{2}$를 이용해 Predictive Distribution을 구할 수 있는지 살펴보겠습니다. 우선 $\theta$의 Posterior 분포인 $p(\theta | D)$를 볼게요. Posterior 분포를 자세히 보기 위해 Bayes Rule을 이용해 Likelihood와 Prior의 곱 형태로 나타내 보겠습니다.</p>
<p>$$
p(\theta | D) = \frac{p(D | \theta) p(\theta)}{p(D)} = \frac{p(D | \theta) p(\theta)}{\int p(D | \theta) p(\theta) d\theta}
$$</p>
<p>Likelihood, Prior, 그리고 데이터 $D$의 분포인 $p(D)$를 안다면 Posterior 확률을 구할 수 있다는 걸 알 수 있습니다. 하지만 여전히 구하기는 어렵습니다. Likelihood인 $p(D | \theta)$는 비교적 쉽게 알 수 있지만 Prior인 $p(\theta)$는 모르는 경우가 많습니다. 혹시 Prior를 알고 있거나 적당한 분포로 가정하더라도 이번엔 분모에 들어있는 데이터의 분포 $p(D)$를 또 모르겠습니다. $p(D)$ 대신 $\int p(D | \theta) p(\theta) d\theta$를 계산하려고 해도 적분이 까다롭습니다.</p>
<p>그래서 아까 말했듯이 일반적으로 우리는 $\theta$의 Posterior 분포를 직접 계산하지는 않습니다. 대신 점추정 기법을 이용해 $\theta$를 대충 추정하는 걸로 만족합니다. 다시 설명해볼게요. 위 수식대로라면 우리는 $D$에 따라 $\theta$가 가질 수 있는 조건부 Posterior 확률 분포 전체를 구해야합니다. 하지만 이게 너무 어려우니 확률 분포 전체를 구하는 건 포기하고, 대신 $\theta$를 가장 그럴듯한 하나의 값으로 추정을 해버리겠다는 것이지요.</p>
<p>$\theta$를 하나의 값으로 추정하면 까다로운 부분이 전부 사라집니다. 만약 우리가 $\theta$를 $\hat{\theta}$로 추정했다고 하면 수식으로 다음과 같이 나타낼 수 있습니다.</p>
<p>$$p(y|x) \approx \int p(y | x, \theta) p(\theta | D) d\theta \approx p(y | x, \hat{\theta})$$</p>
<p>결국 $\theta$를 하나의 값 $\hat{\theta}$로 추정하면, $p(y | x, \hat{\theta})$가 우리가 처음에 원했던 $p(y | x)$를 추정하게 되는 모양입니다. 이것이 바로 우리가 머신러닝 모델을 학습시킬 때 많이 사용하는 시나리오입니다. 혹시 회귀모델이나 딥러닝 등 지도학습 머신러닝 모델을 학습시켜본 경험이 있다면, 십중팔구 모델의 파라미터를 확률분포가 아니라 그냥 고정된 하나의 값으로 구했을 겁니다. 이건 위에서 본 것과 같이 Posterior 분포 전체를 구하기는 어려우니 파라미터의 점추정치를 구하는 것이 됩니다. 그리고 구한 하나의 파라미터 값으로 모델을 고정하고 인풋 데이터 $x$가 들어올 때 모델에서 계산한 $y$를 예측값으로 내보냅니다.</p>
<p>물론 원래라면 $\theta$의 Posterior 분포를 구해야 할 것을 점추정을 해버렸으니 부작용도 있습니다. 바로 오버피팅이에요. 지도학습에서 오버피팅이 생기는 이유가 여기에 있습니다. 데이터 $D$를 이용해 $\theta$값을 하나로 추정하기 때문에 만약 데이터가 부족하거나 질이 안 좋을 경우 $\theta$의 추정치가 부정확해지고 이는 오버피팅으로 이어집니다. 그럼 점추정을 하지 말고 $\theta$의 Posterior를 구해서 모델을 만들면 데이터가 부족하더라도 오버피팅이 안 일어난다는 뜻인가요? 그렇게 볼 수 있습니다. 물론 이게 데이터가 부족해도 예측을 잘하는 『갓☆모델』을 만들 수 있다는 뜻은 아닙니다. Posterior 분포를 구했다고 하더라도 데이터가 부족하다면 Posterior는 Prior에 가까워집니다. Prior 분포가 데이터를 잘 나타내지 못한다면 예측된 분포 역시 부정확할 것이고, 만약 Prior를 잘 몰라서 대충 두루뭉술한 정규분포로 가정해서 사용했다면 모델의 예측값도 두루뭉술해집니다. 인풋 $x$가 들어왔을 때 $y$값이 이것도 될 수 있고 저것도 될 수 있는, 그런 애매한 분포를 반환해준다는 뜻이에요. 냅다 확신하듯 결과를 뱉어주는 오버피팅된 모델보다 이쪽이 나은지는 뭐 경우에 따라 다를 것 같습니다.</p>
<h3 id="3-모델의-파라미터를-추정하는-방법">3. 모델의 파라미터를 추정하는 방법<a hidden class="anchor" aria-hidden="true" href="#3-모델의-파라미터를-추정하는-방법">#</a></h3>
<p>자, Posterior 분포는 구하기 어려우니 대신 $\theta$를 하나의 값 $\hat{\theta}$로 점추정한다는 것 까지 이야기가 이어졌습니다. 그럼 이제부터 어떻게 이 값을 추정하는지 살펴보도록 합시다. 가장 흔하게 사용되는 방법은 바로 Maximum Likelihood Estimation(MLE)를 이용해 $\theta$를 추정하는 것입니다. 즉, $\theta$의 Likelihood를 가장 크게 만들어주는 값으로 $\theta$를 추정하겠다는 이야기지요. 아래 최적화 문제를 푸는 것과 같습니다.</p>
<p>$$\hat{\theta} = \arg \max_{\theta} p(D | \theta)$$</p>
<p>이 시나리오에서 데이터 $D$ 안에는 보통 우리가 구하고자 하는 오리지널 분포 $p(y | x)$에서 독립적으로 샘플링 된 샘플들이 들어있습니다. 샘플링된 인풋, 타겟 데이터의 집합을 $X_{D}$, $Y_{D}$라고 해볼게요. 그럼 다음과 같이 식을 정리할 수 있습니다.</p>
<p>$$\begin{align}<br>
\hat{\theta} &amp;= \arg \max_{\theta} p(D | \theta) \\
&amp;= \arg \max_{\theta} p(X_{D}, Y_{D} | \theta) \\
&amp;= \arg \max_{\theta} \frac{p(Y_{D}, X_{D}, \theta)}{p(\theta)} \\
&amp;= \arg \max_{\theta} \frac{p(Y_{D}, X_{D}, \theta)}{p(X_{D})p(\theta)} \\
&amp;= \arg \max_{\theta} \frac{p(Y_{D}, X_{D}, \theta)}{p(X_{D}, \theta)} \\
&amp;= \arg \max_{\theta} p(Y_{D} | X_{D}, \theta) \\
\end{align}$$</p>
<p>$X_{D}$와 $Y_{D}$에는 각각 $n$개의 데이터가 들어있다고 하겠습니다. 풀어서 쓰면 $x_1, x_2, \cdots x_n$과 $y_1, y_2, \cdots y_n$이 들어있어요. 이 $(x_{i}, y_{i})$ 쌍을 서로 독립적으로 샘플링됐다고 했으니 수식을 다음과 같이 추가로 전개할 수 있습니다.</p>
<p>$$\begin{align}
\hat{\theta} &amp;= \arg \max_{\theta} p(Y_{D} | X_{D} \theta) \\
&amp;= \arg \max_{\theta} \prod_{i=1}^{n} p(y_{i} | x_{i}, \theta) \tag{3} \label{3}
\end{align}$$</p>
<p>이 수식 $\eqref{3}$을 이용하면 $\theta$의 MLE를 구할 수 있습니다. 데이터셋 $D$에 들어있는 데이터 샘플들이 발생할 확률이 가장 커지도록 $\theta$의 값을 추정하는 것이지요. 수식 $\eqref{3}$을 $\theta$에 대해 미분해서 값이 가장 커지게 만들어주는 $\theta$를 계산하면 되겠습니다.</p>
<p>하지만 사실 일반적으로 수식 $\eqref{3}$을 그대로 계산에 사용하는 일은 별로 없습니다. 왜냐하면 수식 $\eqref{3}$의 모양을 보면 서로 독립인 확률을 여러 번 곱해주는 모양인데 별로 좋은 모양이 아닙니다. 1보다 작은 확률을 $n$번 곱하다보면 값이 지나치게 0에 가까워져서 컴퓨터로 계산할 때 문제가 발생할 수 있거든요. Underflow가 발생합니다. 이런 문제를 예방하기 위해 우리는 식 $\eqref{3}$에 $\log$를 씌워서 곱셈을 덧셈 형태로 바꿀 겁니다. $\log$를 씌워도 전체 수식을 가장 크게 만드는 $\hat{\theta}$값은 동일하기 때문에 최적화 문제의 답은 변하지 않습니다.</p>
<p>$$\begin{align}
\hat{\theta} &amp;= \arg \max_{\theta} \prod_{i=1}^{n} p(y_{i} | x_{i}, \theta) \\
&amp;= \arg \min_{\theta} \sum_{i=1}^{n} \left[ -\log p(y_{i} | x_{i}, \theta) \right] \tag{4} \label{4}
\end{align}$$</p>
<p>수식 $\eqref{4}$를 보면 $\log$를 씌워서 확률의 곱셈을 덧셈 형식으로 바꾼 것 이외에도 $-1$을 곱해서 $\arg \max$를 $\arg \min$으로 바꾼 걸 알 수 있습니다. 이런 수학 최적화 문제는 보통 목적식을 최대화 하는 문제 보다는 최소화 문제를 기준으로 쓰는 경우가 관습적으로 많기 때문에 $-1$을 곱해서 최소화 문제로 바꿔줍니다. 이렇게 Likelihood에 $\log$를 씌우고 $-1$을 곱한 것을 Negative Log-Likelihood(NLL)라고 부릅니다. 다시 말해, MLE로 구한 $\theta$의 점추정치는 NLL을 가장 작게 만드는 $\theta$의 점추정치라고도 표현할 수 있습니다. 완전히 똑같은 의미입니다.</p>
<p>또 다른 관점에서도 바라볼 수 있습니다. $D$ 안에 데이터가 $n$개 들어있다고 했으니 위 수식을 $n$으로 나눠볼게요.</p>
<p>$$\begin{align}
\hat{\theta} &amp;= \arg \min_{\theta} \sum_{i} \left[ -\log p(y_{i} | x_{i}, \theta) \right] \\
&amp;= \arg \min_{\theta} \sum_{i} \left[ -\frac{1}{n} \log p(y_{i} | x_{i}, \theta) \right] \\
&amp;= \arg \min_{\theta} \sum_{i} \left[ -p(x_{i}, y_{i}) \log p(y_{i} | x_{i}, \theta) \right] \\
&amp;= \arg \min_{\theta} \sum_{i} \left[ -p(y_{i} | x_{i}) \log p(y_{i} | x_{i}, \theta) \right] \\
&amp;= \arg \min_{\theta} H(p_{\text{data}}, p_{\text{model}}) \tag{5} \label{5}
\end{align}$$</p>
<p>왜 $1/n$이 $p(x_{i}, y_{i})$가 되냐면 이건 Empirical Distribution입니다. 우리가 $n$개의 $(x, y)$ 데이터를 가지고 있으니 그 중 하나인 $(x_i, y_i)$가 발생할 확률은 경험적으로 $1/n$ 정도가 된다는 것이지요. 즉, 수식 $\eqref{5}$에서 $p_{\text{data}}$는 실재 데이터의 분포라기 보다는 데이터셋에서 유추한 경험적인 Empirical 분포입니다. $p_{\text{model}}$은 $\theta$에 따른 모델의 데이터 분포, $p(y_{i} | x_{i}, \theta)$입니다. 결국 수식 $\eqref{5}$은 NLL을 가장 작게 만드는 $\theta$의 추정치는 $p_{\text{data}}$와 $p_{\text{model}}$의 Corss Entropy를 가장 작게 만드는 $\hat{\theta}$와 같다는 뜻을 나타냅니다. 지도학습 모델을 학습시킬 때 Cross Entropy Loss라는 걸 이용하는 경우가 많은데, 수식 $\eqref{5}$를 이용하는 것이지요.</p>
<p>조금만 더 나아가 볼게요. 수식 $\eqref{5}$에서 상수를 더하거나 빼도 $\hat{\theta}$의 값은 변하지 않습니다. 따라서 다음과 같이 수식을 고쳐쓸 수 있습니다.</p>
<p>$$\begin{aligned}
\hat{\theta} &amp;= \arg \min_{\theta} H(p_{\text{data}}, p_{\text{model}}) \\
&amp;= \arg \min_{\theta} \left[ H(p_{\text{data}}, p_{\text{model}}) - H(p_{\text{data}}) \right] \\
&amp;= \arg \min_{\theta} D_{KL}(p_{\text{data}} || p_{\text{model}})
\end{aligned}$$</p>
<p>이번엔 KL-Divergence로 수식이 정리되었습니다. $p_{\text{data}}$와 $p_{\text{model}}$의 KL-Divergence를 가장 작게 만드는 $\theta$의 추정치도 역시 같은 의미가 됩니다. 정리해보겠습니다. MLE를 이용해 모델의 파라미터 $\theta$의 추정치를 구하는 건 아래와 같이 네 가지로 표현할 수 있었습니다.</p>
<ol>
<li>Likelihood를 가장 크게 만드는(MLE) $\theta$를 구한다.</li>
<li>NLL을 가장 작게 만드는 $\theta$를 구한다.</li>
<li>Cross Entropy를 가장 작게 만드는 $\theta$를 구한다.</li>
<li>KL-Divergence를 가장 작게 만드는 $\theta$를 구한다.</li>
</ol>
<p>서로 다른 용어로 써있지만 결국 전부 같은 말입니다. 위 네 용어 모두 머신러닝에서 자주 등장하는 용어인데, 서로 따로따로 쓰이면 복잡해보이지만 이제 우리는 전부 같은 뜻이라는 걸 알았어요.</p>
<p>자, 이렇게 조건부 확률 $p(y|x)$ 이야기 부터 시작해서 모델의 파라미터 $\theta$를 점추정하여 근사하는 과정까지 살펴보았습니다. 물론 실전에서 머신러닝 모델을 지도학습 시킬 때에는 이런 과정은 생각하지 않아도 되는 경우가 대부분입니다. 계산은 컴퓨터가 해주고 학습 알고리즘은 똑똑하신 분들이 이미 다 짜주셨으니, 우린 그대로 가져다 쓰면 됩니다. 하지만 머신러닝 모델을 지도학습시키는게 무엇인지, 데이터로 모델의 파라미터를 구하는 것이 어떤 의미인지를 이해하고 대입해 볼 수 있다면 이런 내용을 공부하는 것도 의미가 없지는 않을 것 같습니다.</p>
<h3 id="참고-자료">참고 자료<a hidden class="anchor" aria-hidden="true" href="#참고-자료">#</a></h3>
<p>Bishop, Christopher M. <a href="https://link.springer.com/book/9780387310732">&ldquo;Pattern Recognition and Machine Learning&rdquo;</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="http://repun.github.io/">MLBlog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
