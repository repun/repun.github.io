<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>CTC 디코딩을 위한 Prefix Beam Search | MemoBlog</title>
<meta name="keywords" content="">
<meta name="description" content="이번 글은 Prefix Beam Search 알고리즘에 대해 정리하는 글입니다. Prefix Beam Search는 CTC(Connectionist Temporal Classification)를 이용해 학습된 모델의 디코딩에 사용됩니다. 평범한 Beam Search 알고리즘에서 CTC 디코딩에 맞게 살짝 변형시킨 알고리즘이 바로 Prefix Beam Search에요. 그러니 당연히 Prefix Beam Search에 대해 알기 위해서는 CTC와 Beam Search, 두 알고리즘에 대해 알고 있어야 합니다. 그래야 Prefix Beam Search 알고리즘이 왜 필요하고 어떻게 동작하는지 이해할 수 있습니다.
이 글은 Prefix Beam Search를 이해하는 데에 초점을 맞출 예정이에요.">
<meta name="author" content="">
<link rel="canonical" href="http://repun.github.io/posts/prefix_beam_search/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.9d4f844eaa4f78f307fe7b60e91f30525e084db78986cd1660839e63f5a041cb.css" integrity="sha256-nU&#43;ETqpPePMH/ntg6R8wUl4ITbeJhs0WYIOeY/WgQcs=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="http://repun.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://repun.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://repun.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://repun.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="http://repun.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  }
};
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
  <meta property="og:title" content="CTC 디코딩을 위한 Prefix Beam Search" />
<meta property="og:description" content="이번 글은 Prefix Beam Search 알고리즘에 대해 정리하는 글입니다. Prefix Beam Search는 CTC(Connectionist Temporal Classification)를 이용해 학습된 모델의 디코딩에 사용됩니다. 평범한 Beam Search 알고리즘에서 CTC 디코딩에 맞게 살짝 변형시킨 알고리즘이 바로 Prefix Beam Search에요. 그러니 당연히 Prefix Beam Search에 대해 알기 위해서는 CTC와 Beam Search, 두 알고리즘에 대해 알고 있어야 합니다. 그래야 Prefix Beam Search 알고리즘이 왜 필요하고 어떻게 동작하는지 이해할 수 있습니다.
이 글은 Prefix Beam Search를 이해하는 데에 초점을 맞출 예정이에요." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://repun.github.io/posts/prefix_beam_search/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-16T20:47:24+09:00" />
<meta property="article:modified_time" content="2022-10-16T20:47:24+09:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="CTC 디코딩을 위한 Prefix Beam Search"/>
<meta name="twitter:description" content="이번 글은 Prefix Beam Search 알고리즘에 대해 정리하는 글입니다. Prefix Beam Search는 CTC(Connectionist Temporal Classification)를 이용해 학습된 모델의 디코딩에 사용됩니다. 평범한 Beam Search 알고리즘에서 CTC 디코딩에 맞게 살짝 변형시킨 알고리즘이 바로 Prefix Beam Search에요. 그러니 당연히 Prefix Beam Search에 대해 알기 위해서는 CTC와 Beam Search, 두 알고리즘에 대해 알고 있어야 합니다. 그래야 Prefix Beam Search 알고리즘이 왜 필요하고 어떻게 동작하는지 이해할 수 있습니다.
이 글은 Prefix Beam Search를 이해하는 데에 초점을 맞출 예정이에요."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://repun.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "CTC 디코딩을 위한 Prefix Beam Search",
      "item": "http://repun.github.io/posts/prefix_beam_search/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "CTC 디코딩을 위한 Prefix Beam Search",
  "name": "CTC 디코딩을 위한 Prefix Beam Search",
  "description": "이번 글은 Prefix Beam Search 알고리즘에 대해 정리하는 글입니다. Prefix Beam Search는 CTC(Connectionist Temporal Classification)를 이용해 학습된 모델의 디코딩에 사용됩니다. 평범한 Beam Search 알고리즘에서 CTC 디코딩에 맞게 살짝 변형시킨 알고리즘이 바로 Prefix Beam Search에요. 그러니 당연히 Prefix Beam Search에 대해 알기 위해서는 CTC와 Beam Search, 두 알고리즘에 대해 알고 있어야 합니다. 그래야 Prefix Beam Search 알고리즘이 왜 필요하고 어떻게 동작하는지 이해할 수 있습니다.\n이 글은 Prefix Beam Search를 이해하는 데에 초점을 맞출 예정이에요.",
  "keywords": [
    
  ],
  "articleBody": "이번 글은 Prefix Beam Search 알고리즘에 대해 정리하는 글입니다. Prefix Beam Search는 CTC(Connectionist Temporal Classification)를 이용해 학습된 모델의 디코딩에 사용됩니다. 평범한 Beam Search 알고리즘에서 CTC 디코딩에 맞게 살짝 변형시킨 알고리즘이 바로 Prefix Beam Search에요. 그러니 당연히 Prefix Beam Search에 대해 알기 위해서는 CTC와 Beam Search, 두 알고리즘에 대해 알고 있어야 합니다. 그래야 Prefix Beam Search 알고리즘이 왜 필요하고 어떻게 동작하는지 이해할 수 있습니다.\n이 글은 Prefix Beam Search를 이해하는 데에 초점을 맞출 예정이에요. 그래서 CTC와 Beam Search에 대한 설명은 Prefix Beam Search의 이해에 필요한 정도로만 간단하게 정리하고 넘어가도록 하겠습니다. CTC와 Beam Search의 더 자세한 내용은 다른 문헌과 자료를 함께 참고하는걸 추천해요.\n1. Connectionist Temporal Classification CTC 알고리즘은 시계열에 따라 구분되어 라벨링 되어있지 않은 시퀀스 데이터를 학습시키는 방법으로 제안되었습니다. 이게 도대체 무슨 소리인지 모르겠으니 예를 들어볼게요. CTC가 가장 잘 사용되는 분야가 바로 ASR(Automatic Speech Recognition) 모델 학습입니다. ASR은 다른 말로 하면 Speech-to-Text에요. 즉, 사람이 말을 하면 해당 음성 데이터를 이용해 무슨말을 한 건지 텍스트로 받아적는 모델입니다. 예를 들어, $\\text{hello}$라는 단어를 발음한 3초 정도의 음성 데이터가 있다고 해봅시다. ASR 모델을 학습시켜서 이 음성 데이터를 넣었을 때 $\\text{hello}$라는 문자열이 예측되도록 하는 것이 목적입니다. 이 3초 길이의 음성 데이터를 0.1초 간격으로 잘라 총 30개의 음성 프레임을 만든 뒤, ASR 모델에 넣어 각 프레임 별로 어떤 발음인지 분류 한다고 해봅시다. 예시를 들자면 대충 아래 그림과 같은 구조에요.\n음성 데이터를 받아 문자를 예측하는 ASR 구조 예시\r위 그림을 보면 ASR 모델은 음성 데이터의 각 프레임 별로 현재 음성이 발음 *, e, h, l, o 중 어디에 해당하는지 분류(Classification)합니다. 참고로 *는 비어있다는(blank) 뜻이에요. 그리고 위 그림의 표에서 각 프레임 별로 붉은색으로 칠해진 부분이 바로 ASR 모델이 가장 Likelihood가 높다고 예측한 문자라고 합시다. 전체 30프레임의 결과를 전부 합치면 ASR 모델이 음성 데이터를 통해 예측한 시퀀스는 다음과 같습니다.\n$$ \\text{****hhh**eeee***lll*lllooo****} $$\n위 시퀀스에서 연속으로 중복된 부분을 하나로 합치고,\n$$ \\text{*h*e*l*lo*} $$\n비어있는 $\\text{*}$를 삭제하면,\n$$ \\text{hello} $$\n우리가 원하던 $\\text{hello}$ 라는 문자열이 됩니다! 참고로 $\\text{hello}$의 $\\text{ll}$ 부분은 l이 연속으로 두 번 들어가기 위해서 l과 l 사이에 적어도 하나의 *가 있어야 합니다. 그러니까, $\\text{ll*l}$은 압축 후에 $\\text{ll}$이라는 문자열이 되지만, $\\text{llll}$은 압축 후에 $\\text{l}$이 되어버려요.\nCTC라는 방법론이 등장하기 이전에는 ASR 모델을 학습시키기 위해서는 음성 데이터의 시간에 따라 화자가 어떤 문자를 발음 했는지 라벨링된 데이터가 필요했습니다. 예를 들어, 음성 파일을 사람이 듣고, 0.5에서 0.6초는 h, 0.8에서 1.0초는 e, 1.2에서 1.4초는 l, 이런식으로 라벨링을 해줬어야 했지요. 시간과 노력이 많이 들어가는 작업인데다가, 단어의 발음이라는게 시간에 따라 명확하게 구분되는 것도 아니기 때문에 어려운 점이 있었습니다.\nCTC는 굳이 이런 라벨링이 없어도 시퀀스 데이터를 학습할 수 있도록 제안된 방법입니다. CTC를 이용하면 $\\text{hello}$라는 문자열로 완성되는 모든 시퀀스의 Likelihood를 전부 더해 최대화하는 식으로 모델이 학습됩니다(MLE). 예를 들어, 아래 시퀀스 모두 똑같이 $\\text{hello}$라는 문자열을 나타냅니다.\n$$\\text{**hh***eeeee***ll*lll**oo****}$$ $$\\text{******heeell*llll*oooo********}$$ $$\\text{****hhh******eel*ll***ooo*****}$$ $$\\text{*****hhhhh*eelllll*****llloo**}$$ $$\\text{**hhel**lll**ooo**************}$$\n예시는 5개이지만 이 외에도 $\\text{hello}$를 표현할 수 있는 엄청나게 많은 조합이 가능할 겁니다. CTC는 이런 모든 조합을 전부 고려해 모델을 학습합니다. 즉, $\\text{hello}$라고 발음한 음성 데이터가 ASR 모델을 통과하면 문자열 $\\text{hello}$로 압축될 수 있는 어떤 시퀀스를 예측하도록 모델이 학습되는 것이지요. 물론 저 수많은 조합을 무지성으로 나열해서 고려했다가는 계산이 매우 복잡해집니다. 그래서 Dynamic Programming을 이용해 효율적으로 모든 조합을 따지는 것이 CTC 알고리즘의 핵심입니다.\n그렇다면 CTC로 학습된 모델을 디코딩 할때는 어떨까요? 지금은 단순하게 각 프레임 별로 h가 맞을지 e가 맞을지 분류했지만, 모델은 사실 각 프레임 별로 어떤 문자가 가장 그럴듯한지 확률 분포를 반환할 겁니다. 예를 들면, 음성 데이터의 0.7초에 해당하는 프레임의 발음이 h일 확률이 0.6, e일 확률이 0.4, 이런 식이겠지요. 물론 0.6이 0.4보다 크니 h가 맞다고 결정하고 넘어갈 수도 있지만, 그렇게 할 경우 최종적으로 예측된 문자열이 정확하지 않을 수 있습니다. 왜냐하면 h가 아닌 e를 선택하는 쪽이 전체적인 시퀀스 관점에서 더 확률이 높은 문자열을 만들 수 있을지도 모르기 때문이지요. 그래서 CTC 디코딩에는 Prefix Beam Search라는 Beam Search가 살짝 변형된 알고리즘을 주로 사용하게 됩니다. Prefix Beam Search에 대해 본격적으로 이야기 하기 전에 기본 버전의 Beam Search에 대해 먼저 살펴보고 갈게요.\n2. Beam Search Beam Search는 가장 유효한 $k$개의 노드만 남겨가며 BFS(Breadth-First Search)를 하는 휴리스틱 방법입니다. BFS는 너비를 우선적으로 트리를 탐색하는 방법인데 트리가 너무 커질 경우에는 끝까지 탐색하는데 어마어마한 계산이 필요할 수 있습니다. Beam Search는 각 깊이에서 가장 유효한 $k$개의 노드만 남겨가며 계산량을 줄여 탐색하는 방법이에요. 이 $k$를 Beam Width라고 부릅니다. 예를 들면 아래 그림과 같습니다.\nBFS(왼쪽)와 Beam Width가 2인 Beam Search(오른쪽)\rBFS는 위 그림의 왼쪽과 같이 트리를 탐색합니다. 각 노드 안에 적힌 숫자는 탐색의 순서를 의미해요. BFS는 이름에서 알 수 있다시피 트리의 각 노드를 탐색하는데 깊이보다 너비를 우선적으로 탐색합니다. 자식 노드를 탐색하기 전에 같은 깊이에 있는 형제 노드들을 우선적으로 탐색하지요. 어쨌든 결과적으로 BFS는 트리의 모든 노드를 탐색하게 됩니다.\n그리고 위 그림의 오른쪽 방법은 Beam Width가 2인 Beam Search입니다. 기본적으로는 BFS와 탐색 순서가 같지만, 더 깊이 탐색 하기 전에 노드를 Beam Width개 만큼만 남겨두고 잘라낸다는 점이 다릅니다. 잘라내는 기준은 물론 필요에 따라 다르게 정의할 수 있습니다. 위 그림에서는 Beam Width가 2이기 때문에, 더 깊이 탐색하기 전에 붉은 색으로 칠해진 2개씩의 노드만 남기고 그 외 노드는 더 이상 탐색하지 않습니다. Beam Search는 BFS와는 다르게 트리의 모든 노드를 탐색하지는 못합니다. 위 그림을 보면 BFS는 20개의 노드를 전부 탐색하지만 Beam Search는 11개의 노드만 탐색하는 선에서 끝났습니다. 그래서 Beam Search는 가장 좋은 해를 항상 찾아내지는 못할 수도 있습니다. 하지만 트리가 넓고 큰 경우 BFS에 비해 탐색 시간과 메모리를 줄여줄 수 있습니다. Beam Width가 크면 클수록 트리의 더 많은 부분을 탐색하고, Beam Width가 작을수록 가장 그럴듯한 노드를 기준으로 트리의 일부만 탐색하게 됩니다.\nBeam Search가 흔하게 사용되는 예시로는 GPT와 같은 생성형 언어 모델이 있습니다. 언어 모델은 주어진 문자열의 다음에 어떤 토큰이 오는게 가장 그럴듯한지 확률 분포를 반환해요. 예를 들어, 오늘 저녁 이라는 문자열이 언어 모델에게 주어졌다면 언어 모델은 그 뒤에 메뉴라는 토큰이 올 확률이 0.5, 날씨라는 토큰이 올 확률은 0.2, 식사라는 토큰이 올 확률은 0.3, 발가락이라는 토큰이 올 확률은 0.0, 이런 식입니다. 가장 확률이 높은 메뉴라는 토큰을 선택한다면 주어진 문자열과 합쳐져 오늘 저녁 메뉴라는 문자열이 되겠지요. 이 문자열을 또 언어 모델에 넣고 다음 토큰을 예측할 수 있습니다. 이 과정을 반복하면 그럴듯하고 자연스러운 문장을 만들어낼 수 있지요.\n하지만 단순히 그때 그때 가장 확률이 높은 토큰을 선택하는 것은 좋지 않을 수 있습니다. 당장은 메뉴라는 토큰의 확률이 가장 높았지만, 길게 보면 오늘 저녁 식사 함께 어때요 라는 문장이 가장 확률이 높을 수 있기 때문이지요. 이 경우 메뉴 보다는 식사 라는 토큰을 선택하는게 결과적으로 더 그럴듯한 문장을 생성할 수 있다는 뜻이 됩니다. 그래서 언어 모델 생성에는 Beam Search를 이용해 다음 토큰을 탐색하는 경우가 많습니다. 아래 그림과 같아요.\n생성형 언어모델 디코딩에 사용하는 Beam Search 예시\r위 그림의 각 노드 안에 들어있는 글자가 탐색하는 토큰이고, 위에 파란색으로 적힌 숫자는 각 토큰의 확률입니다. 메뉴라는 토큰이 식사라는 토큰보다 확률이 높았지만, 다음 탐색까지 고려했을 때, 식사 함께라는 토큰을 생성하는 확률이 0.21로 메뉴는이라는 토큰을 생성할 확률인 0.20보다 높습니다. 이런 식으로 전체적인 관점에서 그럴듯한 문장을 생성하기 위해 언어 모델에서는 Beam Search를 이용해 디코딩하는 경우가 많이 있습니다. 물론 생성 가능한 모든 토큰을 고려하는게 수학적인 관점에서 가장 정확하겠지만, 언어 모델이 생성할 수 있는 전체 토큰은 보통 수천에서 수만, 그 이상도 갈 수 있기 때문에 Beam Search를 사용해 근사하는 것이지요.\n3. Prefix Beam Search 이제 다시 CTC 이야기로 돌아와 봅시다. CTC로 학습한 모델은 시간 프레임 별로 Classification 예측 결과를 내놓게 됩니다. 방금 본 언어 모델의 Beam Search 예시와 기본적으로 유사해요. 당장 확률이 높은 문자를 선택하는 것은 전체 시퀀스 관점에서는 오히려 좋지 않은 선택이 될 수 있습니다. 그래서 언어 모델과 마찬가지로 Beam Search를 사용해 디코딩을 하게 됩니다. $\\text{hello}$라는 문자열을 예측하는 ASR 모델을 다시 생각해볼게요.\nASR 모델의 Beam Search 예시\r예를 들자면 위 그림과 같이 생각해 볼 수 있습니다. 가장 확률이 높은 $k$(=2)개의 노드를 남기면서 이후 프레임으로 탐색해 나가 그럴듯한 시퀀스를 찾아냅니다. 하지만 문제가 있습니다. 위 그림에서 결과적으로 남아있는 두 개의 시퀀스는 아래와 같습니다.\n$$\\text{hhhe}$$ $$\\text{h*ee}$$\n첫번째 시퀀스와 두번째 시퀀스 모두 압축하면 $\\text{he}$라는 똑같은 문자열이 됩니다. 우리는 결과적으로 어떤 문자열이 가장 그럴듯한지를 찾고싶은 것이기 때문에 이건 문제가 있습니다. 즉, 우리는 최종적으로 $\\text{hello}$라는 문자열과 $\\text{hellelo}$라는 문자열 중 어떤게 더 그럴듯한지를 알고싶은 것이지 어차피 압축하면 $\\text{hello}$라는 똑같은 문자열이 나올 서로 다른 시퀀스들을 남기고 싶은게 아니라는 뜻이에요. 이런 문제를 해결하기 위해 CTC 디코딩에는 Beam Search를 살짝 변형해서 사용하게 됩니다. 모델이 특정 시점까지 예측한 문자열을 Prefix라고 부르는데, 바로 이 Prefix를 고려하는 Beam Search, 이름하야 Prefix Beam Search입니다.\n자, 우리는 결국 최종적으로 가장 그럴듯한 문자열이 무엇인지를 찾고싶은 겁니다. 서로 같은 문자열로 압축될 수 있는 여러 시퀀스들은 하나의 Beam으로 생각하고 싶어요. 만약 같은 문자열을 나타내는 서로 다른 Beam이 있다면 두 Beam의 확률을 서로 더해서 합쳐줄 수 있습니다. 아래 그림과 같아요.\n같은 Prefix는 같은 Beam으로 둔다\r위 그림 예시에서 Beam으로 관리하는 것은 압축 이후의 문자열입니다. 엣지에 표시된 동그라미 안의 파란 숫자는 해당 단계에서 선택한 문자에요. 하지만 특정 단계에서 서로 다른 문자를 선택하더라도 압축 이후의 문자열은 같을 수 있습니다. 예를 들어, $\\text{h}$이후에 h와 e를 선택하든, *와 e를 선택하든, 압축 이후 문자열은 $\\text{he}$로 같습니다. 그러니 결국 하나의 Beam으로 합쳐지지요. 두 시퀀스를 선택할 확률 역시 서로 합쳐야 합니다. 즉, $\\text{he}$라는 문자열의 Beam은 $\\text{he}$라는 문자열이 생성될 수 있는 시퀀스들의 확률을 합해서 가지고 있다는 뜻이에요.\n한가지 집고 넘어가야 할 점은 같은 문자열이라도 끝이 *(blank)로 끝나는 것과 그렇지 않은 것을 구분해서 저장하고 있다는 점입니다. 예를 들어, $\\text{h}$ 이후 h를 선택한 경우와 *를 선택한 경우, 모두 압축 이후 문자열은 $\\text{h}$로 같으므로 서로 같은 Beam이지만 내부적으로는 *로 끝난 경우와 그렇지 않은 경우를 구분해서 확률을 저장합니다. 왜냐하면 그 이후에 어떤 문자가 오느냐에 따라 문자열이 달라질 수 있기 때문이에요. 위 그림에서 보면 $\\text{h}$와 $\\text{h*}$는 하나의 Beam에 들어가있지만 서로 구분해서 표시해둔 것이 보입니다. 이후에 또 다시 h를 선택하게 될 경우, 끝이 *로 끝났냐 아니냐에 따라 압축 이후 문자열이 $\\text{h}$와 $\\text{hh}$로 달라집니다.\n여기까지가 Prefix Beam Search의 기본적인 아이디어입니다. 이제부터 더 자세히 들어가볼게요. 아래는 Prefix Beam Search의 전체 과정을 나타내는 Pseudo 코드입니다.\n$$\\begin{align} \\text{1.}\u0026 \\ p_{b}(\\phi, 0) \\gets 1 \\\\ \\text{2.}\u0026 \\ p_{nb}(\\phi, 0) \\gets 0 \\\\ \\text{3.}\u0026 \\ A_{\\text{prev}} \\gets \\{\\phi\\} \\\\ \\text{4.}\u0026 \\ \\textbf{for } t \\textbf{ in } 1, 2, \\cdots, T \\textbf{ do} \\\\ \\text{5.}\u0026 \\ \\qquad A_{\\text{next}} \\gets \\{\\} \\\\ \\text{6.}\u0026 \\ \\qquad \\textbf{for } l \\textbf{ in } A_{\\text{prev}} \\textbf{ do} \\\\ \\text{7.}\u0026 \\ \\qquad \\qquad \\textbf{for } c \\textbf{ in } \\Sigma \\textbf{ do} \\\\ \\text{8.}\u0026 \\ \\qquad \\qquad \\qquad \\textbf{if } c = \\text{blank} \\textbf{ then} \\\\ \\text{9.}\u0026 \\ \\qquad \\qquad \\qquad \\qquad p_b(l, t) \\gets p(c, t) \\left( p_b(l, t-1) + p_{nb}(l, t-1) \\right) \\\\ \\text{10.}\u0026 \\ \\qquad \\qquad \\qquad \\qquad \\text{add } l \\text{ to } A_{\\text{next}} \\\\ \\text{11.}\u0026 \\ \\qquad \\qquad \\qquad \\textbf{else} \\\\ \\text{12.}\u0026 \\ \\qquad \\qquad \\qquad \\qquad l^{+} \\gets \\text{concatenate } l \\text{ and } c \\\\ \\text{13.}\u0026 \\ \\qquad \\qquad \\qquad \\qquad \\textbf{if } c = l_{\\text{end}} \\textbf{ then} \\\\ \\text{14.}\u0026 \\ \\qquad \\qquad \\qquad \\qquad \\qquad p_{nb}(l^+, t) \\gets p(c, t) p_b(l, t-1) \\\\ \\text{15.}\u0026 \\ \\qquad \\qquad \\qquad \\qquad \\qquad p_{nb}(l, t) \\gets p(c, t) p_{nb}(l, t-1) \\\\ \\text{16.}\u0026 \\ \\qquad \\qquad \\qquad \\qquad \\textbf{else} \\\\ \\text{17.}\u0026 \\ \\qquad \\qquad \\qquad \\qquad \\qquad p_{nb}(l, t) \\gets p(c, t) \\left( p_b(l, t-1) + p_{nb}(l, t-1) \\right) \\\\ \\text{18.}\u0026 \\ \\qquad \\qquad \\qquad \\qquad \\textbf{end if} \\\\ \\text{19.}\u0026 \\ \\qquad \\qquad \\qquad \\qquad \\textbf{if } l^+ \\textbf{ not in } A_{\\text{prev}} \\textbf{ then} \\\\ \\text{20.}\u0026 \\ \\qquad \\qquad \\qquad \\qquad \\qquad p_{b}(l^+, t) \\gets p(\\text{blank}, t) \\left( p_b(l^+, t-1) + p_{nb}(l^+, t-1) \\right) \\\\ \\text{21.}\u0026 \\ \\qquad \\qquad \\qquad \\qquad \\qquad p_{nb}(l^+, t) \\gets p(c, t) p_{nb}(l^+, t-1) \\\\ \\text{22.}\u0026 \\ \\qquad \\qquad \\qquad \\qquad \\textbf{end if} \\\\ \\text{23.}\u0026 \\ \\qquad \\qquad \\qquad \\qquad \\text{add } l^+ \\text{ to } A_{\\text{next}} \\\\ \\text{24.}\u0026 \\ \\qquad \\qquad \\qquad \\textbf{end if} \\\\ \\text{25.}\u0026 \\ \\qquad \\qquad \\textbf{end for} \\\\ \\text{26.}\u0026 \\ \\qquad \\textbf{end for} \\\\ \\text{27.}\u0026 \\ \\qquad A_{\\text{prev}} \\gets k \\text{ most probable prefixes in } A_{\\text{next}} \\\\ \\text{28.}\u0026 \\ \\textbf{end for} \\\\ \\text{28.}\u0026 \\ \\textbf{return } 1 \\text{ most probable prefix in } A_{\\text{prev}} \\\\ \\end{align}$$\n뭔가 복잡해 보이지만 방금 우리가 살펴본 기본 아이디어 그대로입니다. 우선 기호들을 정리할게요. $A_{\\text{prev}}$가 우리가 관리하는 $k$개의 Beam들이 들어있는 집합입니다. 위 코드의 3번째 줄에서 이 집합에 초기 문자열($\\phi$)을 넣고 초기화 합니다. 그리고 알고리즘을 통해 $A_{\\text{prev}}$ 안에 들어있는 각 Beam들에 대해(6줄) 다음 문자가 뭐가 들어갈지 탐색합니다. 그리고 탐색한 결과 나온 새로운 문자열들을 $A_{\\text{next}}$에 넣습니다(10, 23줄). 이 중에서 $k$개의 가장 그럴듯한 문자열만 남겨서 $A_{\\text{prev}}$에 다시 넣고(27줄) 반복하는 형식이에요.\n$\\Sigma$는 전체 문자의 집합입니다. 우리가 계속 예시로 봐왔던 $\\text{hello}$를 읽어내는 ASR 모델 기준으로는 blank인 *를 포함한 h, e, l, o의 집합이 되겠지요. 일반적으로는 blank와 공백(space) 등을 포함한 알파벳 전체의 집합이 될 겁니다. 각 Beam에 대해서 그 다음에 어떤 문자가 들어갈지 $\\Sigma$에서 하나씩 찾아서 살펴보게 됩니다(7줄).\n위 코드에서 중요한건 $p_{n}$과 $p_{nb}$입니다. 둘 모두 key-value를 가진 Map 형태의 자료구조인데, $p_{b}$는 마지막이 blank(*)로 끝난 문자열의 확률을 저장하고, $p_{nb}$는 마지막이 blank로 끝나지 않은(non-blank) 문자열의 확률을 저장합니다. 아까 예시 그림을 설명하면서 같은 문자열로 압축되더라도 마지막이 *로 끝난 경우과 그렇지 않은 경우를 내부적으로 구분하여 저장한다고 했었지요. $p_{b}$와 $p_{nb}$가 그 역할을 하는 거에요. $p_{b}(l, t)$는 시간 $t$에서 끝이 *로 끝나고 문자열 $l$로 압축되는 시퀀스들의 총 확률을 나타냅니다. 예를 들어, $p_{b}(\\text{he}, 3)$은 $\\text{he}$로 압축될 수 있는 시퀀스, $\\text{hee}$, $\\text{hhe}$, $\\text{h*e}$, $\\text{he*}$, $\\text{*he}$ 확률의 합을 저장하고 있겠지요.\n$p$는 CTC로 학습된 모델이 예측한 확률 분포입니다. ASR이라면 $p(c, t)$는 모델이 시간 프레임 $t$에 문자 $c$에 준 확률이에요. 처음 ASR 구조 예시 그림에서 5개의 문자에 대해 30프레임 간의 예측 결과를 나타냈던 $5\\times30$ 크기의 테이블이 바로 $p$라고 보면 됩니다.\n마지막으로 위 Pseudo 코드에서 $p_b$와 $p_{nb}$에 확률을 할당하는 $\\gets$ 기호는 만약 해당 key에 value가 이미 있다면 더해준다는 의미로 생각해야 합니다. 예를 들어, $p_{b}(\\text{he}, 3) \\gets 0.3$ 이라고 해볼게요. $p_{b}(\\text{he}, 3)$가 기존에 없었다면 $0.3$을 할당하고, 만약 $p_{b}(\\text{he}, 3)$ 안에 $0.2$가 이미 할당돼있다면 $0.3$을 더해 $0.5$를 넣어주게 됩니다.\n자, 기호가 무슨 의미인지 정리했으니 이제 코드를 이해하는 것은 비교적 간단합니다. 새로 추가 하려는 문자가 어떤 것인지에 따라 총 3가지 케이스가 있어요. 나누어서 하나씩 생각해볼게요.\n새로 추가하려는 문자가 blank(*)인 경우 (8-10줄) 새로 추가하려는 문자가 기존 문자열의 마지막 문자와 같은 문자인 경우 (13-15줄) 새로 추가하려는 문자가 기존 문자열의 마지막 문자와 다른 문자인 경우 (16-17줄) 먼저 1번 케이스입니다. 코드의 8-10번째 줄을 볼게요. 만약 기존 문자열에 추가하려는 새로운 문자가 blank(*)라면 기존 문자열의 끝이 blank이든 그렇지 않든 문자열이 변하지 않습니다. 아까 봤던 그림에서 해당 되는 부분을 빨갛게 표시해서 다시 그려볼게요.\n새로 추가하는 문자가 blank인 경우\r$\\text{h}$에 *를 더하든 $\\text{h*}$에 *를 더하든 압축하면 똑같이 $\\text{h}$가 됩니다. 그러니 $p_{b}$와 $p_{nb}$ 확률을 서로 더해서 blank의 확률과 곱해주는 것이지요(9줄).\n2번 케이스입니다. 새로 추가하려는 문자가 blank가 아니고 기존 문자열의 마지막과 같은 문자를 더하려는 경우입니다(13-15줄). 같은 문자열일지라도 마지막 문자가 *였는지 그렇지 않았는지에 따라 결과가 달라집니다. 마지막이 *로 끝났었다면 새로 추가하는 문자가 중복되겠고, *로 끝나지 않았었다면 압축 후 기존 문자열과 합쳐집니다. 마찬가지로 아래 그림에 표시해 볼게요.\n새로 추가하는 문자가 이전 문자열의 마지막과 같은 문자인 경우\r$\\text{h}$에 h를 더하는 것과, $\\text{h*}$에 h를 더하는 것이 서로 결과가 다르지요 그래서 $p_n$과 $p_{bn}$을 서로 구분하여 따로 확률을 계산해 줍니다(14, 15줄).\n3번 케이스입니다. 새로 추가하려는 문자가 기존 문자열의 마지막과 다른 문자라면 기존 문자열의 마지막이 *이든 그렇지 않든 결과가 같습니다.\n새로 추가하는 문자가 이전 문자열의 마지막과 같은 문자인 경우\r그러니 $p_n$과 $p_{bn}$의 확률을 서로 더해서 하나의 Beam으로 합쳐준 뒤, 추가하려는 문자의 확률과 곱해주면 됩니다(17줄).\n이렇게 해서 $A_{\\text{prev}}$에 저장된 문자열 별로 다음 문자가 추가될 확률을 계산합니다. 그리고 새로 추가된 문자열을 $A_{\\text{next}}$에 저장하지요. 그리고 27번 줄에서 보듯이 가장 확률이 높은 $k$개의 문자열을 새로 뽑아 $A_{\\text{prev}}$에 넣고 전체 과정을 반복하는 겁니다. 참고로 $A_{\\text{next}}$안에 새로 추가된 문자열들의 확률을 비교할 때에는 $p_{b}$와 $p_{nb}$를 더해서 생각해야 합니다. 그래야 해당 문자열이 나올 전체 확률을 알 수 있어요. 다시 말해서, 시간 $t$에서 문자열 $l$의 확률은 아래와 같이 구할 수 있습니다.\n$$p_{b}(l, t) + p_{nb}(l, t)$$\n다음 이야기를 하기 전에 마지막으로 19-22번째 줄을 집고 넘어갈게요. Beam Search는 미리 정해둔 $k$개만큼의 노드만 남겨두고 탐색을 하기 때문에 모든 경우의 수를 전부 따져보지는 못합니다. 그러니 어느 정도는 오차가 생길 수 있겠지요. 19-22번 줄은 이런 경우를 일부 완화해 줍니다. 예를 들어, 만약 시간 $t-1$에서 $\\text{he}$라는 문자열과 $\\text{hel}$이라는 문자열이 나왔는데 안타깝게도 $\\text{hel}$이라는 문자열은 상위 $k$개의 그럴듯한 문자열 순위에 들지 못해서 잘렸다고 해봅시다. 그러니까 $A_{\\text{prev}}$ 안에 $\\text{he}$는 들어갔지만 $\\text{hel}$는 못 들어간 겁니다. 그런데 시간 $t$에서 $\\text{he}$ 문자열 뒤에 l이 붙어서 $\\text{hel}$라는 문자열이 나왔다고 해봅시다. 이 경우 우리는 $t$에서 문자열 $\\text{hel}$가 나올 정확한 확률을 계산하지 못할 수 있습니다. 왜냐하면, $t$에서 $\\text{hel}$가 나올 확률은 $\\text{he}$에 l이 붙을 확률, $\\text{hel}$에 *가 붙을 확률, $\\text{hel}$에 l이 붙을 확률을 모두 고려해서 더해주어야 하는데, $t-1$에서 $\\text{hel}$를 잘라버렸으니 뒤에 두 확률은 더해지지 않기 때문이지요. 그래서 새로 생성된 문자열이 $A_{\\text{prev}}$에 없다면 $t-1$ 시점의 $p_b$와 $p_{nb}$ 안에 혹시 확률이 있는지 확인해 더해주는 겁니다. (물론 없다면 아무것도 더해지지 않으니 변하는 건 없습니다.)\n4. Language Model in ASR 이제 거의 다 왔습니다. 기본적인 Prefix Beam Search는 여태까지 살펴본 것과 같이 동작합니다. 여기서는 CTC로 학습된 ASR 모델에서 더 정확한 디코딩을 위해 언어 모델을 활용하는 방법을 알아볼게요. 언어 모델은 ASR 모델이 음성 데이터만으로 판단하기 어려운 부분을 도와줄 수 있습니다. 예를 들어, $\\text{hello}$라는 단어를 발음한 음성이 녹음 된 파일을 ASR을 통해 디코딩 했더니 $\\text{helo}$ 혹은 $\\text{hellow}$라는 문자열이 나올 수 있습니다. 발음은 서로 비슷하니 그럴 수도 있지요. 하지만 문법이나 철자, 의미가 맞지 않게 됩니다. 언어 모델을 사용하면 이런 문제를 완화할 수 있습니다. 아까 Beam Search 예시에서 보았듯이, 언어 모델은 다음에 어떤 토큰이 오는게 가장 그럴듯한지 확률 분포를 반환해 준다고 했지요. 그러니 일반적으로 생각해봤을 때 같은 발음의 음성일 지라도 $\\text{hello}$를 의미했을 확률이 $\\text{helo}$나 $\\text{hellow}$보다는 훨씬 높을 겁니다. 즉, 언어 모델을 고려하면 $\\text{helo}$나 $\\text{hellow}$ 보다는 $\\text{hello}$로 디코딩 될 확률을 높여줄 수 있지요. 한국어를 예로 들자면, 발음이 똑같더라도 “팔이 아프다\"가 “파리 아프다\"보다 훨씬 자연스러운 문장이니 언어 모델의 도움을 받아 앞의 문장으로 디코딩 할 수 있습니다.\n수식을 이용해 살펴볼게요. 어떤 문자열 $W$가 있다고 해봅시다. ASR 모델이 음성 데이터 $X$를 받아 $W$라는 문자열로 예측할 확률을 $p_{ctc}(W | X)$라고 해볼게요. 여태까지는 언어 모델을 고려하지 않았으므로 Prefix Beam Search를 통해 바로 이 확률이 커지는 문자열 $W$를 찾는 과정이었습니다.\n$$\\arg \\max_{W} p_{ctc}(W | X)$$\n여기에 우리는 추가로 언어 모델을 고려하려고 합니다. $W$라는 문자열이 언어 모델이 보기에도 자연스러운(생성 확률이 높은) 문자열이면 좋겠지요. 언어 모델에서 $W$가 생성될 확률을 $p_{lm}(W)$라고 하겠습니다. 두 확률의 곱을 크게 만들어 주는 $W$라면 ASR과 언어 모델을 모두 고려한 문자열이라고 볼 수 있겠습니다.\n$$\\arg \\max_{W} p_{ctc}(W | X)p_{lm}(W)$$\n여기에 추가로 우리는 ASR 모델과 언어 모델이 반영되는 비중을 조절하고 싶습니다. Application에 따라 ASR 모델과 언어 모델을 어느 정도 비중으로 중요하게 생각할지 다를 수 있지요. $\\alpha$라는 Hyperparameter를 추가해 아래와 같이 나타내겠습니다.\n$$p_{ctc}(W | X)p_{lm}(W)^{\\alpha}\\tag{1}\\label{1}$$\n실제 구현에서는 여기에 추가적으로 $W$의 길이를 고려해주기도 합니다. 아래 식과 같아요.\n$$p_{ctc}(W)p_{lm}(W)^{\\alpha} L(W)^{\\beta}\\tag{2}\\label{2}$$\n$L(W)$는 문자열 $W$의 길이(토큰 개수)를 구하는 함수입니다. 토큰의 수를 고려하지 않을 경우 짧은 문자열이 예측되는 경우가 많이 있기 때문에 토큰 수가 많을수록 전체 확률에 약간 가산점을 주는 방식입니다. CTC 모델 디코딩은 매번 새로운 문자를 탐색하고 시퀀스를 만들고 확률을 계산합니다. 하지만 토큰 단위로 학습된 언어 모델은 그러지 못해요. 언어 모델 기준으로 새로운 토큰이 예측될 때만 확률을 계산할 수 있습니다. 예를 들어 볼게요. 음성 데이터를 인식해서 아래와 같은 두 시퀀스가 나왔다고 해봅시다.\n$$\\text{**hhel**lll**ooo****} \\to \\text{hello}$$\n$$\\text{**hhe**l************} \\to \\text{hel}$$\n안타깝게도 우리의 언어 모델에 $\\text{hel}$이라는 토큰은 없다고 할게요. 즉, 첫번째 시퀀스는 $\\text{hello}$라는 완전한 단어(토큰)가 예측되었고 두번째 시퀀스는 그렇지 않지요. 문자열의 길이를 고려하지 않는다면 두 문자열의 확률은 아까 봤던 식 $\\eqref{1}$을 이용해 아래과 같이 나타낼 수 있습니다.\n$$p_{ctc}(\\text{hello} | X)p_{lm}(\\text{hello})^{\\alpha}$$ $$p_{ctc}(\\text{hel} | X)$$\n두번째 시퀀스는 토큰이 완성되지 않았으니 언어 모델 확률을 계산할 수 없습니다. 그러면 상대적으로 첫번째 시퀀스보다는 두번째 시퀀스가 확률이 높을 수 있습니다. (물론 잘 학습된 ASR 모델이라면 음성 데이터를 듣고 올바른 문자열에 높은 확률을 주기는 하겠지만요!) 즉, 토큰이 적어 문자열이 짧을수록 언어 모델 확률을 그만큼 덜 곱하게 되니 식 $\\eqref{1}$로 계산한 확률이 커지는 경향이 생기게 되고, 최종적으로 짧은 길이의 문자열이 예측되는 경우가 많아질 수 있습니다. 이런 일을 방지하기 위해 예측되는 문자열의 길이가 길어지면 그만큼 보정해 문자열 길이가 예측에 크게 영향을 주지 않도록 하는 아이디어입니다.\n$L(W)$가 토큰 개수 + 1로 계산된다고 해볼게요. 즉, $L(\\text{hello}) = 2$이고, $L(\\text{hel}) = 1$입니다. 그러면 식 $\\eqref{2}$를 이용해 두 시퀀스의 확률을 아래와 같이 계산할 수 있습니다.\n$$p_{ctc}(\\text{hello} | X)p_{lm}(\\text{hello})^{\\alpha} 2^{\\beta}$$ $$p_{ctc}(\\text{hel} | X) 1^{\\beta}$$\n$\\beta$가 커질수록 첫번째 시퀀스에 더 많은 가산점을 줄 수 있습니다. 어떤 $\\beta$가 적당한지는 언어 모델과 데이터, $\\alpha$에 따라 다를 수 있으니 직접 시도해 보고 잘 작동하는 $\\beta$를 찾아야 합니다.\n여기까지가 언어 모델을 디코딩에 활용하는 방법이었습니다. 그렇다면 이 내용을 아까 열심히 살펴봤던 Pseudo 코드에는 어떻게 반영해야 할까요? 기본적으로 새로운 토큰이 완성될 때마다 해당 토큰의 언어 모델 확률을 추가로 곱해주면 됩니다. 12번째 줄에서 새로운 문자열 $l^+$를 탐색할 때, 만약 새로운 토큰이 완성되었다면 $p_b(l^+, t)$나 $p_{nb}(l^+, t)$를 업데이트할 때 $p_{lm}(l^+ | l)^{\\alpha}$을 추가로 곱해주면 됩니다. 그리고 27줄에서 $k$개의 문자열을 선택하기 위해 $p_{b}$와 $p_{nb}$를 더할 때는 $L(l)^{\\beta}$를 곱해주면 되지요. 여기서 또 다시 Pseudo 코드를 전부 쓰지는 않을게요. 언어 모델까지 포함된 Prefix Beam Search의 전체 Pseudo 코드는 원 논문에 있습니다.\n이렇게 해서 Prefix Beam Search에 대해 정리했습니다. 아무래도 CTC 모델이 가장 자주 사용되는 분야가 ASR이다보니 이 글도 그렇고 다른 여러 논문이나 문헌에도 ASR을 기준으로 삼거나 예시를 드는 경우가 많이 있습니다. 하지만 꼭 ASR에만 활용되라는 법은 없지요. 손글씨나 입술의 모양으로 텍스트를 예측하는 모델에도 사용될 수 있습니다. 이 글에 정리된 Prefix Beam Search 내용이 CTC 모델을 디코딩하거나, 이미 구현된 디코딩 알고리즘을 이해하는데 도움이 된다면 좋을 것 같습니다.\n참고 자료 Graves et al. “Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks” Hannun et al. “First-Pass Large Vocabulary Continuous Speech Recognition using Bi-Directional Recurrent DNNs” Hannun, Awni Y. “Sequence Modeling With CTC” Borgholt, Lasse “CTC Networks and Language Models: Prefix Beam Search Explained” ",
  "wordCount" : "3334",
  "inLanguage": "en",
  "datePublished": "2022-10-16T20:47:24+09:00",
  "dateModified": "2022-10-16T20:47:24+09:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://repun.github.io/posts/prefix_beam_search/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "MemoBlog",
    "logo": {
      "@type": "ImageObject",
      "url": "http://repun.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://repun.github.io/" accesskey="h" title="MemoBlog (Alt + H)">MemoBlog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      CTC 디코딩을 위한 Prefix Beam Search
    </h1>
    <div class="post-meta"><span title='2022-10-16 20:47:24 +0900 KST'>October 16, 2022</span>

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#1-connectionist-temporal-classification" aria-label="1. Connectionist Temporal Classification">1. Connectionist Temporal Classification</a></li>
                <li>
                    <a href="#2-beam-search" aria-label="2. Beam Search">2. Beam Search</a></li>
                <li>
                    <a href="#3-prefix-beam-search" aria-label="3. Prefix Beam Search">3. Prefix Beam Search</a></li>
                <li>
                    <a href="#4-language-model-in-asr" aria-label="4. Language Model in ASR">4. Language Model in ASR</a></li>
                <li>
                    <a href="#%ec%b0%b8%ea%b3%a0-%ec%9e%90%eb%a3%8c" aria-label="참고 자료">참고 자료</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>이번 글은 Prefix Beam Search 알고리즘에 대해 정리하는 글입니다. Prefix Beam Search는 CTC(Connectionist Temporal Classification)를 이용해 학습된 모델의 디코딩에 사용됩니다. 평범한 Beam Search 알고리즘에서 CTC 디코딩에 맞게 살짝 변형시킨 알고리즘이 바로 Prefix Beam Search에요. 그러니 당연히 Prefix Beam Search에 대해 알기 위해서는 CTC와 Beam Search, 두 알고리즘에 대해 알고 있어야 합니다. 그래야 Prefix Beam Search 알고리즘이 왜 필요하고 어떻게 동작하는지 이해할 수 있습니다.</p>
<p>이 글은 Prefix Beam Search를 이해하는 데에 초점을 맞출 예정이에요. 그래서 CTC와 Beam Search에 대한 설명은 Prefix Beam Search의 이해에 필요한 정도로만 간단하게 정리하고 넘어가도록 하겠습니다. CTC와 Beam Search의 더 자세한 내용은 다른 문헌과 자료를 함께 참고하는걸 추천해요.</p>
<h3 id="1-connectionist-temporal-classification">1. Connectionist Temporal Classification<a hidden class="anchor" aria-hidden="true" href="#1-connectionist-temporal-classification">#</a></h3>
<p><a href="https://www.cs.toronto.edu/~graves/icml_2006.pdf">CTC 알고리즘</a>은 시계열에 따라 구분되어 라벨링 되어있지 않은 시퀀스 데이터를 학습시키는 방법으로 제안되었습니다. 이게 도대체 무슨 소리인지 모르겠으니 예를 들어볼게요. CTC가 가장 잘 사용되는 분야가 바로 ASR(Automatic Speech Recognition) 모델 학습입니다. ASR은 다른 말로 하면 Speech-to-Text에요. 즉, 사람이 말을 하면 해당 음성 데이터를 이용해 무슨말을 한 건지 텍스트로 받아적는 모델입니다. 예를 들어, $\text{hello}$라는 단어를 발음한 3초 정도의 음성 데이터가 있다고 해봅시다. ASR 모델을 학습시켜서 이 음성 데이터를 넣었을 때 $\text{hello}$라는 문자열이 예측되도록 하는 것이 목적입니다. 이 3초 길이의 음성 데이터를 0.1초 간격으로 잘라 총 30개의 음성 프레임을 만든 뒤, ASR 모델에 넣어 각 프레임 별로 어떤 발음인지 분류 한다고 해봅시다. 예시를 들자면 대충 아래 그림과 같은 구조에요.</p>
<p>

<figure>
  <img src="/posts/images/asr_model.png" alt="asr_model.png" loading="lazy" />
  <figcaption style="text-align: center; color: gray">음성 데이터를 받아 문자를 예측하는 ASR 구조 예시</figcaption>
</figure>
</p>
<p>위 그림을 보면 ASR 모델은 음성 데이터의 각 프레임 별로 현재 음성이 발음 <code>*</code>, <code>e</code>, <code>h</code>, <code>l</code>, <code>o</code> 중 어디에 해당하는지 분류(Classification)합니다. 참고로 <code>*</code>는 비어있다는(blank) 뜻이에요. 그리고 위 그림의 표에서 각 프레임 별로 붉은색으로 칠해진 부분이 바로 ASR 모델이 가장 Likelihood가 높다고 예측한 문자라고 합시다. 전체 30프레임의 결과를 전부 합치면 ASR 모델이 음성 데이터를 통해 예측한 시퀀스는 다음과 같습니다.</p>
<p>$$
\text{****hhh**eeee***lll*lllooo****}
$$</p>
<p>위 시퀀스에서 연속으로 중복된 부분을 하나로 합치고,</p>
<p>$$
\text{*h*e*l*lo*}
$$</p>
<p>비어있는 $\text{*}$를 삭제하면,</p>
<p>$$
\text{hello}
$$</p>
<p>우리가 원하던 $\text{hello}$ 라는 문자열이 됩니다! 참고로 $\text{hello}$의 $\text{ll}$ 부분은 <code>l</code>이 연속으로 두 번 들어가기 위해서 <code>l</code>과 <code>l</code> 사이에 적어도 하나의 <code>*</code>가 있어야 합니다. 그러니까, $\text{ll*l}$은 압축 후에 $\text{ll}$이라는 문자열이 되지만, $\text{llll}$은 압축 후에 $\text{l}$이 되어버려요.</p>
<p>CTC라는 방법론이 등장하기 이전에는 ASR 모델을 학습시키기 위해서는 음성 데이터의 시간에 따라 화자가 어떤 문자를 발음 했는지 라벨링된 데이터가 필요했습니다. 예를 들어, 음성 파일을 사람이 듣고, 0.5에서 0.6초는 <code>h</code>, 0.8에서 1.0초는 <code>e</code>, 1.2에서 1.4초는 <code>l</code>, 이런식으로 라벨링을 해줬어야 했지요. 시간과 노력이 많이 들어가는 작업인데다가, 단어의 발음이라는게 시간에 따라 명확하게 구분되는 것도 아니기 때문에 어려운 점이 있었습니다.</p>
<p>CTC는 굳이 이런 라벨링이 없어도 시퀀스 데이터를 학습할 수 있도록 제안된 방법입니다. CTC를 이용하면 $\text{hello}$라는 문자열로 완성되는 모든 시퀀스의 Likelihood를 전부 더해 최대화하는 식으로 모델이 학습됩니다(MLE). 예를 들어, 아래 시퀀스 모두 똑같이 $\text{hello}$라는 문자열을 나타냅니다.</p>
<p>$$\text{**hh***eeeee***ll*lll**oo****}$$
$$\text{******heeell*llll*oooo********}$$
$$\text{****hhh******eel*ll***ooo*****}$$
$$\text{*****hhhhh*eelllll*****llloo**}$$
$$\text{**hhel**lll**ooo**************}$$</p>
<p>예시는 5개이지만 이 외에도 $\text{hello}$를 표현할 수 있는 엄청나게 많은 조합이 가능할 겁니다. CTC는 이런 모든 조합을 전부 고려해 모델을 학습합니다. 즉, $\text{hello}$라고 발음한 음성 데이터가 ASR 모델을 통과하면 문자열 $\text{hello}$로 압축될 수 있는 어떤 시퀀스를 예측하도록 모델이 학습되는 것이지요. 물론 저 수많은 조합을 무지성으로 나열해서 고려했다가는 계산이 매우 복잡해집니다. 그래서 Dynamic Programming을 이용해 효율적으로 모든 조합을 따지는 것이 CTC 알고리즘의 핵심입니다.</p>
<p>그렇다면 CTC로 학습된 모델을 디코딩 할때는 어떨까요? 지금은 단순하게 각 프레임 별로 <code>h</code>가 맞을지 <code>e</code>가 맞을지 분류했지만, 모델은 사실 각 프레임 별로 어떤 문자가 가장 그럴듯한지 확률 분포를 반환할 겁니다. 예를 들면, 음성 데이터의 0.7초에 해당하는 프레임의 발음이 <code>h</code>일 확률이 0.6, <code>e</code>일 확률이 0.4, 이런 식이겠지요. 물론 0.6이 0.4보다 크니 <code>h</code>가 맞다고 결정하고 넘어갈 수도 있지만, 그렇게 할 경우 최종적으로 예측된 문자열이 정확하지 않을 수 있습니다. 왜냐하면 <code>h</code>가 아닌 <code>e</code>를 선택하는 쪽이 전체적인 시퀀스 관점에서 더 확률이 높은 문자열을 만들 수 있을지도 모르기 때문이지요. 그래서 CTC 디코딩에는 Prefix Beam Search라는 Beam Search가 살짝 변형된 알고리즘을 주로 사용하게 됩니다. Prefix Beam Search에 대해 본격적으로 이야기 하기 전에 기본 버전의 Beam Search에 대해 먼저 살펴보고 갈게요.</p>
<h3 id="2-beam-search">2. Beam Search<a hidden class="anchor" aria-hidden="true" href="#2-beam-search">#</a></h3>
<p>Beam Search는 가장 유효한 $k$개의 노드만 남겨가며 BFS(Breadth-First Search)를 하는 휴리스틱 방법입니다. BFS는 너비를 우선적으로 트리를 탐색하는 방법인데 트리가 너무 커질 경우에는 끝까지 탐색하는데 어마어마한 계산이 필요할 수 있습니다. Beam Search는 각 깊이에서 가장 유효한 $k$개의 노드만 남겨가며 계산량을 줄여 탐색하는 방법이에요. 이 $k$를 Beam Width라고 부릅니다. 예를 들면 아래 그림과 같습니다.</p>
<p>

<figure>
  <img src="/posts/images/beam_search.png" alt="beam_search.png" loading="lazy" />
  <figcaption style="text-align: center; color: gray">BFS(왼쪽)와 Beam Width가 2인 Beam Search(오른쪽)</figcaption>
</figure>
</p>
<p>BFS는 위 그림의 왼쪽과 같이 트리를 탐색합니다. 각 노드 안에 적힌 숫자는 탐색의 순서를 의미해요. BFS는 이름에서 알 수 있다시피 트리의 각 노드를 탐색하는데 깊이보다 너비를 우선적으로 탐색합니다. 자식 노드를 탐색하기 전에 같은 깊이에 있는 형제 노드들을 우선적으로 탐색하지요. 어쨌든 결과적으로 BFS는 트리의 모든 노드를 탐색하게 됩니다.</p>
<p>그리고 위 그림의 오른쪽 방법은 Beam Width가 2인 Beam Search입니다. 기본적으로는 BFS와 탐색 순서가 같지만, 더 깊이 탐색 하기 전에 노드를 Beam Width개 만큼만 남겨두고 잘라낸다는 점이 다릅니다. 잘라내는 기준은 물론 필요에 따라 다르게 정의할 수 있습니다. 위 그림에서는 Beam Width가 2이기 때문에, 더 깊이 탐색하기 전에 붉은 색으로 칠해진 2개씩의 노드만 남기고 그 외 노드는 더 이상 탐색하지 않습니다. Beam Search는 BFS와는 다르게 트리의 모든 노드를 탐색하지는 못합니다. 위 그림을 보면 BFS는 20개의 노드를 전부 탐색하지만 Beam Search는 11개의 노드만 탐색하는 선에서 끝났습니다. 그래서 Beam Search는 가장 좋은 해를 항상 찾아내지는 못할 수도 있습니다. 하지만 트리가 넓고 큰 경우 BFS에 비해 탐색 시간과 메모리를 줄여줄 수 있습니다. Beam Width가 크면 클수록 트리의 더 많은 부분을 탐색하고, Beam Width가 작을수록 가장 그럴듯한 노드를 기준으로 트리의 일부만 탐색하게 됩니다.</p>
<p>Beam Search가 흔하게 사용되는 예시로는 GPT와 같은 생성형 언어 모델이 있습니다. 언어 모델은 주어진 문자열의 다음에 어떤 토큰이 오는게 가장 그럴듯한지 확률 분포를 반환해요. 예를 들어, <strong>오늘 저녁</strong> 이라는 문자열이 언어 모델에게 주어졌다면 언어 모델은 그 뒤에 <strong>메뉴</strong>라는 토큰이 올 확률이 0.5, <strong>날씨</strong>라는 토큰이 올 확률은 0.2, <strong>식사</strong>라는 토큰이 올 확률은 0.3, <strong>발가락</strong>이라는 토큰이 올 확률은 0.0, 이런 식입니다. 가장 확률이 높은 <strong>메뉴</strong>라는 토큰을 선택한다면 주어진 문자열과 합쳐져 <strong>오늘 저녁 메뉴</strong>라는 문자열이 되겠지요. 이 문자열을 또 언어 모델에 넣고 다음 토큰을 예측할 수 있습니다. 이 과정을 반복하면 그럴듯하고 자연스러운 문장을 만들어낼 수 있지요.</p>
<p>하지만 단순히 그때 그때 가장 확률이 높은 토큰을 선택하는 것은 좋지 않을 수 있습니다. 당장은 <strong>메뉴</strong>라는 토큰의 확률이 가장 높았지만, 길게 보면 <strong>오늘 저녁 식사 함께 어때요</strong> 라는 문장이 가장 확률이 높을 수 있기 때문이지요. 이 경우 <strong>메뉴</strong> 보다는 <strong>식사</strong> 라는 토큰을 선택하는게 결과적으로 더 그럴듯한 문장을 생성할 수 있다는 뜻이 됩니다. 그래서 언어 모델 생성에는 Beam Search를 이용해 다음 토큰을 탐색하는 경우가 많습니다. 아래 그림과 같아요.</p>
<p>

<figure>
  <img src="/posts/images/lm_beam_search.png" alt="lm_beam_search.png" loading="lazy" />
  <figcaption style="text-align: center; color: gray">생성형 언어모델 디코딩에 사용하는 Beam Search 예시</figcaption>
</figure>
</p>
<p>위 그림의 각 노드 안에 들어있는 글자가 탐색하는 토큰이고, 위에 파란색으로 적힌 숫자는 각 토큰의 확률입니다. <strong>메뉴</strong>라는 토큰이 <strong>식사</strong>라는 토큰보다 확률이 높았지만, 다음 탐색까지 고려했을 때, <strong>식사 함께</strong>라는 토큰을 생성하는 확률이 0.21로 <strong>메뉴는</strong>이라는 토큰을 생성할 확률인 0.20보다 높습니다. 이런 식으로 전체적인 관점에서 그럴듯한 문장을 생성하기 위해 언어 모델에서는 Beam Search를 이용해 디코딩하는 경우가 많이 있습니다. 물론 생성 가능한 모든 토큰을 고려하는게 수학적인 관점에서 가장 정확하겠지만, 언어 모델이 생성할 수 있는 전체 토큰은 보통 수천에서 수만, 그 이상도 갈 수 있기 때문에 Beam Search를 사용해 근사하는 것이지요.</p>
<h3 id="3-prefix-beam-search">3. Prefix Beam Search<a hidden class="anchor" aria-hidden="true" href="#3-prefix-beam-search">#</a></h3>
<p>이제 다시 CTC 이야기로 돌아와 봅시다. CTC로 학습한 모델은 시간 프레임 별로 Classification 예측 결과를 내놓게 됩니다. 방금 본 언어 모델의 Beam Search 예시와 기본적으로 유사해요. 당장 확률이 높은 문자를 선택하는 것은 전체 시퀀스 관점에서는 오히려 좋지 않은 선택이 될 수 있습니다. 그래서 언어 모델과 마찬가지로 Beam Search를 사용해 디코딩을 하게 됩니다. $\text{hello}$라는 문자열을 예측하는 ASR 모델을 다시 생각해볼게요.</p>
<p>

<figure>
  <img src="/posts/images/asr_beam_search.png" alt="asr_beam_search.png" loading="lazy" />
  <figcaption style="text-align: center; color: gray">ASR 모델의 Beam Search 예시</figcaption>
</figure>
</p>
<p>예를 들자면 위 그림과 같이 생각해 볼 수 있습니다. 가장 확률이 높은 $k$(=2)개의 노드를 남기면서 이후 프레임으로 탐색해 나가 그럴듯한 시퀀스를 찾아냅니다. 하지만 문제가 있습니다. 위 그림에서 결과적으로 남아있는 두 개의 시퀀스는 아래와 같습니다.</p>
<p>$$\text{hhhe}$$
$$\text{h*ee}$$</p>
<p>첫번째 시퀀스와 두번째 시퀀스 모두 압축하면 $\text{he}$라는 똑같은 문자열이 됩니다. 우리는 결과적으로 어떤 <strong>문자열</strong>이 가장 그럴듯한지를 찾고싶은 것이기 때문에 이건 문제가 있습니다. 즉, 우리는 최종적으로 $\text{hello}$라는 문자열과 $\text{hellelo}$라는 문자열 중 어떤게 더 그럴듯한지를 알고싶은 것이지 어차피 압축하면 $\text{hello}$라는 똑같은 문자열이 나올 서로 다른 시퀀스들을 남기고 싶은게 아니라는 뜻이에요. 이런 문제를 해결하기 위해 CTC 디코딩에는 Beam Search를 살짝 변형해서 사용하게 됩니다. 모델이 특정 시점까지 예측한 문자열을 Prefix라고 부르는데, 바로 이 Prefix를 고려하는 Beam Search, 이름하야 <a href="https://arxiv.org/abs/1408.2873">Prefix Beam Search입니다</a>.</p>
<p>자, 우리는 결국 최종적으로 가장 그럴듯한 문자열이 무엇인지를 찾고싶은 겁니다. 서로 같은 문자열로 압축될 수 있는 여러 시퀀스들은 하나의 Beam으로 생각하고 싶어요. 만약 같은 문자열을 나타내는 서로 다른 Beam이 있다면 두 Beam의 확률을 서로 더해서 합쳐줄 수 있습니다. 아래 그림과 같아요.</p>
<p>

<figure>
  <img src="/posts/images/asr_prefix_beam_search.png" alt="asr_prefix_beam_search.png" loading="lazy" />
  <figcaption style="text-align: center; color: gray">같은 Prefix는 같은 Beam으로 둔다</figcaption>
</figure>
</p>
<p>위 그림 예시에서 Beam으로 관리하는 것은 압축 이후의 문자열입니다. 엣지에 표시된 동그라미 안의 파란 숫자는 해당 단계에서 선택한 문자에요. 하지만 특정 단계에서 서로 다른 문자를 선택하더라도 압축 이후의 문자열은 같을 수 있습니다. 예를 들어, $\text{h}$이후에 <code>h</code>와 <code>e</code>를 선택하든, <code>*</code>와 <code>e</code>를 선택하든, 압축 이후 문자열은 $\text{he}$로 같습니다. 그러니 결국 하나의 Beam으로 합쳐지지요. 두 시퀀스를 선택할 확률 역시 서로 합쳐야 합니다. 즉, $\text{he}$라는 문자열의 Beam은 $\text{he}$라는 문자열이 생성될 수 있는 시퀀스들의 확률을 합해서 가지고 있다는 뜻이에요.</p>
<p>한가지 집고 넘어가야 할 점은 같은 문자열이라도 끝이 <code>*</code>(blank)로 끝나는 것과 그렇지 않은 것을 구분해서 저장하고 있다는 점입니다. 예를 들어, $\text{h}$ 이후 <code>h</code>를 선택한 경우와 <code>*</code>를 선택한 경우, 모두 압축 이후 문자열은 $\text{h}$로 같으므로 서로 같은 Beam이지만 내부적으로는 <code>*</code>로 끝난 경우와 그렇지 않은 경우를 구분해서 확률을 저장합니다. 왜냐하면 그 이후에 어떤 문자가 오느냐에 따라 문자열이 달라질 수 있기 때문이에요. 위 그림에서 보면 $\text{h}$와 $\text{h*}$는 하나의 Beam에 들어가있지만 서로 구분해서 표시해둔 것이 보입니다. 이후에 또 다시 <code>h</code>를 선택하게 될 경우, 끝이 <code>*</code>로 끝났냐 아니냐에 따라 압축 이후 문자열이 $\text{h}$와 $\text{hh}$로 달라집니다.</p>
<p>여기까지가 Prefix Beam Search의 기본적인 아이디어입니다. 이제부터 더 자세히 들어가볼게요. 아래는 Prefix Beam Search의 전체 과정을 나타내는 Pseudo 코드입니다.</p>
<p>$$\begin{align}
\text{1.}&amp; \ p_{b}(\phi, 0) \gets 1 \\
\text{2.}&amp; \ p_{nb}(\phi, 0) \gets 0 \\
\text{3.}&amp; \ A_{\text{prev}} \gets \{\phi\} \\
\text{4.}&amp; \ \textbf{for } t \textbf{ in } 1, 2, \cdots, T \textbf{ do} \\
\text{5.}&amp; \ \qquad A_{\text{next}} \gets \{\} \\
\text{6.}&amp; \ \qquad \textbf{for } l \textbf{ in } A_{\text{prev}} \textbf{ do} \\
\text{7.}&amp; \ \qquad \qquad \textbf{for } c \textbf{ in } \Sigma \textbf{ do} \\
\text{8.}&amp; \ \qquad \qquad \qquad \textbf{if } c = \text{blank} \textbf{ then} \\
\text{9.}&amp; \ \qquad \qquad \qquad \qquad p_b(l, t) \gets p(c, t) \left( p_b(l, t-1) + p_{nb}(l, t-1) \right) \\
\text{10.}&amp; \ \qquad \qquad \qquad \qquad \text{add } l \text{ to } A_{\text{next}} \\
\text{11.}&amp; \ \qquad \qquad \qquad \textbf{else} \\
\text{12.}&amp; \ \qquad \qquad \qquad \qquad l^{+} \gets \text{concatenate } l \text{ and } c \\
\text{13.}&amp; \ \qquad \qquad \qquad \qquad \textbf{if } c = l_{\text{end}} \textbf{ then} \\
\text{14.}&amp; \ \qquad \qquad \qquad \qquad \qquad p_{nb}(l^+, t) \gets p(c, t) p_b(l, t-1) \\
\text{15.}&amp; \ \qquad \qquad \qquad \qquad \qquad p_{nb}(l, t) \gets p(c, t) p_{nb}(l, t-1) \\
\text{16.}&amp; \ \qquad \qquad \qquad \qquad \textbf{else} \\
\text{17.}&amp; \ \qquad \qquad \qquad \qquad \qquad p_{nb}(l, t) \gets p(c, t) \left( p_b(l, t-1) + p_{nb}(l, t-1) \right) \\
\text{18.}&amp; \ \qquad \qquad \qquad \qquad \textbf{end if} \\
\text{19.}&amp; \ \qquad \qquad \qquad \qquad \textbf{if } l^+ \textbf{ not in } A_{\text{prev}} \textbf{ then} \\
\text{20.}&amp; \ \qquad \qquad \qquad \qquad \qquad p_{b}(l^+, t) \gets p(\text{blank}, t) \left( p_b(l^+, t-1) + p_{nb}(l^+, t-1) \right) \\
\text{21.}&amp; \ \qquad \qquad \qquad \qquad \qquad p_{nb}(l^+, t) \gets p(c, t) p_{nb}(l^+, t-1) \\
\text{22.}&amp; \ \qquad \qquad \qquad \qquad \textbf{end if} \\
\text{23.}&amp; \ \qquad \qquad \qquad \qquad \text{add } l^+ \text{ to } A_{\text{next}} \\
\text{24.}&amp; \ \qquad \qquad \qquad \textbf{end if} \\
\text{25.}&amp; \ \qquad \qquad \textbf{end for} \\
\text{26.}&amp; \ \qquad \textbf{end for} \\
\text{27.}&amp; \ \qquad A_{\text{prev}} \gets k \text{ most probable prefixes in } A_{\text{next}} \\
\text{28.}&amp; \ \textbf{end for} \\
\text{28.}&amp; \ \textbf{return } 1 \text{ most probable prefix in } A_{\text{prev}} \\
\end{align}$$</p>
<p>뭔가 복잡해 보이지만 방금 우리가 살펴본 기본 아이디어 그대로입니다. 우선 기호들을 정리할게요. $A_{\text{prev}}$가 우리가 관리하는 $k$개의 Beam들이 들어있는 집합입니다. 위 코드의 3번째 줄에서 이 집합에 초기 문자열($\phi$)을 넣고 초기화 합니다. 그리고 알고리즘을 통해 $A_{\text{prev}}$ 안에 들어있는 각 Beam들에 대해(6줄) 다음 문자가 뭐가 들어갈지 탐색합니다. 그리고 탐색한 결과 나온 새로운 문자열들을 $A_{\text{next}}$에 넣습니다(10, 23줄). 이 중에서 $k$개의 가장 그럴듯한 문자열만 남겨서 $A_{\text{prev}}$에 다시 넣고(27줄) 반복하는 형식이에요.</p>
<p>$\Sigma$는 전체 문자의 집합입니다. 우리가 계속 예시로 봐왔던 $\text{hello}$를 읽어내는 ASR 모델 기준으로는 blank인 <code>*</code>를 포함한 <code>h</code>, <code>e</code>, <code>l</code>, <code>o</code>의 집합이 되겠지요. 일반적으로는 blank와 공백(space) 등을 포함한 알파벳 전체의 집합이 될 겁니다. 각
Beam에 대해서 그 다음에 어떤 문자가 들어갈지 $\Sigma$에서 하나씩 찾아서 살펴보게 됩니다(7줄).</p>
<p>위 코드에서 중요한건 $p_{n}$과 $p_{nb}$입니다. 둘 모두 key-value를 가진 Map 형태의 자료구조인데, $p_{b}$는 마지막이 blank(<code>*</code>)로 끝난 문자열의 확률을 저장하고, $p_{nb}$는 마지막이 blank로 끝나지 않은(non-blank) 문자열의 확률을 저장합니다. 아까 예시 그림을 설명하면서 같은 문자열로 압축되더라도 마지막이 <code>*</code>로 끝난 경우과 그렇지 않은 경우를 내부적으로 구분하여 저장한다고 했었지요. $p_{b}$와 $p_{nb}$가 그 역할을 하는 거에요. $p_{b}(l, t)$는 시간 $t$에서 끝이 <code>*</code>로 끝나고 문자열 $l$로 압축되는 시퀀스들의 총 확률을 나타냅니다. 예를 들어, $p_{b}(\text{he}, 3)$은 $\text{he}$로 압축될 수 있는 시퀀스, $\text{hee}$, $\text{hhe}$, $\text{h*e}$, $\text{he*}$, $\text{*he}$ 확률의 합을 저장하고 있겠지요.</p>
<p>$p$는 CTC로 학습된 모델이 예측한 확률 분포입니다. ASR이라면 $p(c, t)$는 모델이 시간 프레임 $t$에 문자 $c$에 준 확률이에요. 처음 ASR 구조 예시 그림에서 5개의 문자에 대해 30프레임 간의 예측 결과를 나타냈던 $5\times30$ 크기의 테이블이 바로 $p$라고 보면 됩니다.</p>
<p>마지막으로 위 Pseudo 코드에서 $p_b$와 $p_{nb}$에 확률을 할당하는 $\gets$ 기호는 만약 해당 key에 value가 이미 있다면 더해준다는 의미로 생각해야 합니다. 예를 들어, $p_{b}(\text{he}, 3) \gets 0.3$ 이라고 해볼게요. $p_{b}(\text{he}, 3)$가 기존에 없었다면 $0.3$을 할당하고, 만약 $p_{b}(\text{he}, 3)$ 안에 $0.2$가 이미 할당돼있다면 $0.3$을 더해 $0.5$를 넣어주게 됩니다.</p>
<p>자, 기호가 무슨 의미인지 정리했으니 이제 코드를 이해하는 것은 비교적 간단합니다. 새로 추가 하려는 문자가 어떤 것인지에 따라 총 3가지 케이스가 있어요. 나누어서 하나씩 생각해볼게요.</p>
<ol>
<li>새로 추가하려는 문자가 blank(<code>*</code>)인 경우 (8-10줄)</li>
<li>새로 추가하려는 문자가 기존 문자열의 마지막 문자와 같은 문자인 경우 (13-15줄)</li>
<li>새로 추가하려는 문자가 기존 문자열의 마지막 문자와 다른 문자인 경우 (16-17줄)</li>
</ol>
<p>먼저 1번 케이스입니다. 코드의 8-10번째 줄을 볼게요. 만약 기존 문자열에 추가하려는 새로운 문자가 blank(<code>*</code>)라면 기존 문자열의 끝이 blank이든 그렇지 않든 문자열이 변하지 않습니다. 아까 봤던 그림에서 해당 되는 부분을 빨갛게 표시해서 다시 그려볼게요.</p>
<p>

<figure>
  <img src="/posts/images/asr_prefix_beam_search_ex1.png" alt="asr_prefix_beam_search_ex1.png" loading="lazy" />
  <figcaption style="text-align: center; color: gray">새로 추가하는 문자가 blank인 경우</figcaption>
</figure>
</p>
<p>$\text{h}$에 <code>*</code>를 더하든 $\text{h*}$에 <code>*</code>를 더하든 압축하면 똑같이 $\text{h}$가 됩니다. 그러니 $p_{b}$와 $p_{nb}$ 확률을 서로 더해서 blank의 확률과 곱해주는 것이지요(9줄).</p>
<p>2번 케이스입니다. 새로 추가하려는 문자가 blank가 아니고 기존 문자열의 마지막과 같은 문자를 더하려는 경우입니다(13-15줄). 같은 문자열일지라도 마지막 문자가 <code>*</code>였는지 그렇지 않았는지에 따라 결과가 달라집니다. 마지막이 <code>*</code>로 끝났었다면 새로 추가하는 문자가 중복되겠고, <code>*</code>로 끝나지 않았었다면 압축 후 기존 문자열과 합쳐집니다. 마찬가지로 아래 그림에 표시해 볼게요.</p>
<p>

<figure>
  <img src="/posts/images/asr_prefix_beam_search_ex2.png" alt="asr_prefix_beam_search_ex2.png" loading="lazy" />
  <figcaption style="text-align: center; color: gray">새로 추가하는 문자가 이전 문자열의 마지막과 같은 문자인 경우</figcaption>
</figure>
</p>
<p>$\text{h}$에 <code>h</code>를 더하는 것과, $\text{h*}$에 <code>h</code>를 더하는 것이 서로 결과가 다르지요 그래서 $p_n$과 $p_{bn}$을 서로 구분하여 따로 확률을 계산해 줍니다(14, 15줄).</p>
<p>3번 케이스입니다. 새로 추가하려는 문자가 기존 문자열의 마지막과 다른 문자라면 기존 문자열의 마지막이 <code>*</code>이든 그렇지 않든 결과가 같습니다.</p>
<p>

<figure>
  <img src="/posts/images/asr_prefix_beam_search_ex3.png" alt="asr_prefix_beam_search_ex3.png" loading="lazy" />
  <figcaption style="text-align: center; color: gray">새로 추가하는 문자가 이전 문자열의 마지막과 같은 문자인 경우</figcaption>
</figure>
</p>
<p>그러니 $p_n$과 $p_{bn}$의 확률을 서로 더해서 하나의 Beam으로 합쳐준 뒤, 추가하려는 문자의 확률과 곱해주면 됩니다(17줄).</p>
<p>이렇게 해서 $A_{\text{prev}}$에 저장된 문자열 별로 다음 문자가 추가될 확률을 계산합니다. 그리고 새로 추가된 문자열을 $A_{\text{next}}$에 저장하지요. 그리고 27번 줄에서 보듯이 가장 확률이 높은 $k$개의 문자열을 새로 뽑아 $A_{\text{prev}}$에 넣고 전체 과정을 반복하는 겁니다. 참고로 $A_{\text{next}}$안에 새로 추가된 문자열들의 확률을 비교할 때에는 $p_{b}$와 $p_{nb}$를 더해서 생각해야 합니다. 그래야 해당 문자열이 나올 전체 확률을 알 수 있어요. 다시 말해서, 시간 $t$에서 문자열 $l$의 확률은 아래와 같이 구할 수 있습니다.</p>
<p>$$p_{b}(l, t) + p_{nb}(l, t)$$</p>
<p>다음 이야기를 하기 전에 마지막으로 19-22번째 줄을 집고 넘어갈게요. Beam Search는 미리 정해둔 $k$개만큼의 노드만 남겨두고 탐색을 하기 때문에 모든 경우의 수를 전부 따져보지는 못합니다. 그러니 어느 정도는 오차가 생길 수 있겠지요. 19-22번 줄은 이런 경우를 일부 완화해 줍니다. 예를 들어, 만약 시간 $t-1$에서 $\text{he}$라는 문자열과 $\text{hel}$이라는 문자열이 나왔는데 안타깝게도 $\text{hel}$이라는 문자열은 상위 $k$개의 <strong>그럴듯한 문자열 순위</strong>에 들지 못해서 잘렸다고 해봅시다. 그러니까 $A_{\text{prev}}$ 안에 $\text{he}$는 들어갔지만 $\text{hel}$는 못 들어간 겁니다. 그런데 시간 $t$에서 $\text{he}$ 문자열 뒤에 <code>l</code>이 붙어서 $\text{hel}$라는 문자열이 나왔다고 해봅시다. 이 경우 우리는 $t$에서 문자열 $\text{hel}$가 나올 정확한 확률을 계산하지 못할 수 있습니다. 왜냐하면, $t$에서 $\text{hel}$가 나올 확률은 $\text{he}$에 <code>l</code>이 붙을 확률, $\text{hel}$에 <code>*</code>가 붙을 확률, $\text{hel}$에 <code>l</code>이 붙을 확률을 모두 고려해서 더해주어야 하는데, $t-1$에서 $\text{hel}$를 잘라버렸으니 뒤에 두 확률은 더해지지 않기 때문이지요. 그래서 새로 생성된 문자열이 $A_{\text{prev}}$에 없다면 $t-1$ 시점의 $p_b$와 $p_{nb}$ 안에 혹시 확률이 있는지 확인해 더해주는 겁니다. (물론 없다면 아무것도 더해지지 않으니 변하는 건 없습니다.)</p>
<h3 id="4-language-model-in-asr">4. Language Model in ASR<a hidden class="anchor" aria-hidden="true" href="#4-language-model-in-asr">#</a></h3>
<p>이제 거의 다 왔습니다. 기본적인 Prefix Beam Search는 여태까지 살펴본 것과 같이 동작합니다. 여기서는 CTC로 학습된 ASR 모델에서 더 정확한 디코딩을 위해 언어 모델을 활용하는 방법을 알아볼게요. 언어 모델은 ASR 모델이 음성 데이터만으로 판단하기 어려운 부분을 도와줄 수 있습니다. 예를 들어, $\text{hello}$라는 단어를 발음한 음성이 녹음 된 파일을 ASR을 통해 디코딩 했더니 $\text{helo}$ 혹은 $\text{hellow}$라는 문자열이 나올 수 있습니다. 발음은 서로 비슷하니 그럴 수도 있지요. 하지만 문법이나 철자, 의미가 맞지 않게 됩니다. 언어 모델을 사용하면 이런 문제를 완화할 수 있습니다. 아까 Beam Search 예시에서 보았듯이, 언어 모델은 다음에 어떤 토큰이 오는게 가장 그럴듯한지 확률 분포를 반환해 준다고 했지요. 그러니 일반적으로 생각해봤을 때 같은 발음의 음성일 지라도 $\text{hello}$를 의미했을 확률이 $\text{helo}$나 $\text{hellow}$보다는 훨씬 높을 겁니다. 즉, 언어 모델을 고려하면 $\text{helo}$나 $\text{hellow}$ 보다는 $\text{hello}$로 디코딩 될 확률을 높여줄 수 있지요. 한국어를 예로 들자면, 발음이 똑같더라도 &ldquo;팔이 아프다&quot;가 &ldquo;파리 아프다&quot;보다 훨씬 자연스러운 문장이니 언어 모델의 도움을 받아 앞의 문장으로 디코딩 할 수 있습니다.</p>
<p>수식을 이용해 살펴볼게요. 어떤 문자열 $W$가 있다고 해봅시다. ASR 모델이 음성 데이터 $X$를 받아 $W$라는 문자열로 예측할 확률을 $p_{ctc}(W | X)$라고 해볼게요. 여태까지는 언어 모델을 고려하지 않았으므로 Prefix Beam Search를 통해 바로 이 확률이 커지는 문자열 $W$를 찾는 과정이었습니다.</p>
<p>$$\arg \max_{W} p_{ctc}(W | X)$$</p>
<p>여기에 우리는 추가로 언어 모델을 고려하려고 합니다. $W$라는 문자열이 언어 모델이 보기에도 자연스러운(생성 확률이 높은) 문자열이면 좋겠지요. 언어 모델에서 $W$가 생성될 확률을 $p_{lm}(W)$라고 하겠습니다. 두 확률의 곱을 크게 만들어 주는 $W$라면 ASR과 언어 모델을 모두 고려한 문자열이라고 볼 수 있겠습니다.</p>
<p>$$\arg \max_{W} p_{ctc}(W | X)p_{lm}(W)$$</p>
<p>여기에 추가로 우리는 ASR 모델과 언어 모델이 반영되는 비중을 조절하고 싶습니다. Application에 따라 ASR 모델과 언어 모델을 어느 정도 비중으로 중요하게 생각할지 다를 수 있지요. $\alpha$라는 Hyperparameter를 추가해 아래와 같이 나타내겠습니다.</p>
<p>$$p_{ctc}(W | X)p_{lm}(W)^{\alpha}\tag{1}\label{1}$$</p>
<p>실제 구현에서는 여기에 추가적으로 $W$의 길이를 고려해주기도 합니다. 아래 식과 같아요.</p>
<p>$$p_{ctc}(W)p_{lm}(W)^{\alpha} L(W)^{\beta}\tag{2}\label{2}$$</p>
<p>$L(W)$는 문자열 $W$의 길이(토큰 개수)를 구하는 함수입니다. 토큰의 수를 고려하지 않을 경우 짧은 문자열이 예측되는 경우가 많이 있기 때문에 토큰 수가 많을수록 전체 확률에 약간 가산점을 주는 방식입니다. CTC 모델 디코딩은 매번 새로운 문자를 탐색하고 시퀀스를 만들고 확률을 계산합니다. 하지만 토큰 단위로 학습된 언어 모델은 그러지 못해요. 언어 모델 기준으로 새로운 토큰이 예측될 때만 확률을 계산할 수 있습니다. 예를 들어 볼게요. 음성 데이터를 인식해서 아래와 같은 두 시퀀스가 나왔다고 해봅시다.</p>
<p>$$\text{**hhel**lll**ooo****} \to \text{hello}$$</p>
<p>$$\text{**hhe**l************} \to \text{hel}$$</p>
<p>안타깝게도 우리의 언어 모델에 $\text{hel}$이라는 토큰은 없다고 할게요. 즉, 첫번째 시퀀스는 $\text{hello}$라는 완전한 단어(토큰)가 예측되었고 두번째 시퀀스는 그렇지 않지요. 문자열의 길이를 고려하지 않는다면 두 문자열의 확률은 아까 봤던 식 $\eqref{1}$을 이용해 아래과 같이 나타낼 수 있습니다.</p>
<p>$$p_{ctc}(\text{hello} | X)p_{lm}(\text{hello})^{\alpha}$$
$$p_{ctc}(\text{hel} | X)$$</p>
<p>두번째 시퀀스는 토큰이 완성되지 않았으니 언어 모델 확률을 계산할 수 없습니다. 그러면 상대적으로 첫번째 시퀀스보다는 두번째 시퀀스가 확률이 높을 수 있습니다. (물론 잘 학습된 ASR 모델이라면 음성 데이터를 듣고 올바른 문자열에 높은 확률을 주기는 하겠지만요!) 즉, 토큰이 적어 문자열이 짧을수록 언어 모델 확률을 그만큼 덜 곱하게 되니 식 $\eqref{1}$로 계산한 확률이 커지는 경향이 생기게 되고, 최종적으로 짧은 길이의 문자열이 예측되는 경우가 많아질 수 있습니다. 이런 일을 방지하기 위해 예측되는 문자열의 길이가 길어지면 그만큼 보정해 문자열 길이가 예측에 크게 영향을 주지 않도록 하는 아이디어입니다.</p>
<p>$L(W)$가 토큰 개수 + 1로 계산된다고 해볼게요. 즉, $L(\text{hello}) = 2$이고, $L(\text{hel}) = 1$입니다. 그러면 식 $\eqref{2}$를 이용해 두 시퀀스의 확률을 아래와 같이 계산할 수 있습니다.</p>
<p>$$p_{ctc}(\text{hello} | X)p_{lm}(\text{hello})^{\alpha} 2^{\beta}$$
$$p_{ctc}(\text{hel} | X) 1^{\beta}$$</p>
<p>$\beta$가 커질수록 첫번째 시퀀스에 더 많은 가산점을 줄 수 있습니다. 어떤 $\beta$가 적당한지는 언어 모델과 데이터, $\alpha$에 따라 다를 수 있으니 직접 시도해 보고 잘 작동하는 $\beta$를 찾아야 합니다.</p>
<p>여기까지가 언어 모델을 디코딩에 활용하는 방법이었습니다. 그렇다면 이 내용을 아까 열심히 살펴봤던 Pseudo 코드에는 어떻게 반영해야 할까요? 기본적으로 새로운 토큰이 완성될 때마다 해당 토큰의 언어 모델 확률을 추가로 곱해주면 됩니다. 12번째 줄에서 새로운 문자열 $l^+$를 탐색할 때, 만약 새로운 토큰이 완성되었다면 $p_b(l^+, t)$나 $p_{nb}(l^+, t)$를 업데이트할 때 $p_{lm}(l^+ | l)^{\alpha}$을 추가로 곱해주면 됩니다. 그리고 27줄에서 $k$개의 문자열을 선택하기 위해 $p_{b}$와 $p_{nb}$를 더할 때는 $L(l)^{\beta}$를 곱해주면 되지요. 여기서 또 다시 Pseudo 코드를 전부 쓰지는 않을게요. 언어 모델까지 포함된 Prefix Beam Search의 전체 Pseudo 코드는 <a href="https://arxiv.org/abs/1408.2873">원 논문</a>에 있습니다.</p>
<p>이렇게 해서 Prefix Beam Search에 대해 정리했습니다. 아무래도 CTC 모델이 가장 자주 사용되는 분야가 ASR이다보니 이 글도 그렇고 다른 여러 논문이나 문헌에도 ASR을 기준으로 삼거나 예시를 드는 경우가 많이 있습니다. 하지만 꼭 ASR에만 활용되라는 법은 없지요. <a href="https://www.researchgate.net/publication/320296697_Handwritten_digit_string_recognition_by_combination_of_residual_network_and_RNN-CTC">손글씨</a>나 <a href="https://arxiv.org/abs/1803.04988">입술의 모양</a>으로 텍스트를 예측하는 모델에도 사용될 수 있습니다. 이 글에 정리된 Prefix Beam Search 내용이 CTC 모델을 디코딩하거나, 이미 구현된 디코딩 알고리즘을 이해하는데 도움이 된다면 좋을 것 같습니다.</p>
<h3 id="참고-자료">참고 자료<a hidden class="anchor" aria-hidden="true" href="#참고-자료">#</a></h3>
<ol>
<li>Graves et al. <a href="https://www.cs.toronto.edu/~graves/icml_2006.pdf">&ldquo;Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks&rdquo;</a></li>
<li>Hannun et al. <a href="https://arxiv.org/abs/1408.2873">&ldquo;First-Pass Large Vocabulary Continuous Speech Recognition using Bi-Directional Recurrent DNNs&rdquo;</a></li>
<li>Hannun, Awni Y. <a href="https://distill.pub/2017/ctc/">&ldquo;Sequence Modeling With CTC&rdquo;</a></li>
<li>Borgholt, Lasse <a href="https://medium.com/corti-ai/ctc-networks-and-language-models-prefix-beam-search-explained-c11d1ee23306">&ldquo;CTC Networks and Language Models: Prefix Beam Search Explained&rdquo;</a></li>
</ol>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="http://repun.github.io/">MemoBlog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
